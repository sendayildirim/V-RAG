{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical RAG System for Zuleika Dobson\n",
    "\n",
    "Bu notebook, Project Gutenberg'den \"Zuleika Dobson\" kitabını kullanarak hiyerarşik parçalama yöntemiyle bir RAG (Retrieval-Augmented Generation) sistemi oluşturur.\n",
    "\n",
    "**Proje Detayları:**\n",
    "- **Kitap:** Zuleika Dobson by Max Beerbohm\n",
    "- **Dataset:** NarrativeQA (40 test sorusu)\n",
    "- **Vector DB:** Milvus Lite\n",
    "- **Embedding Model:** all-MiniLM-L6-v2\n",
    "- **LLM:** google/gemma-2-2b-it\n",
    "- **Metrikler:** BLEU, ROUGE-1, ROUGE-2, ROUGE-L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Kurulum ve Hazırlık"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Kütüphaneleri Kur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab'da çalışıyorsak, önce proje dosyalarını yükle\n",
    "import os\n",
    "\n",
    "# Colab kontrolü\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Google Colab ortamı tespit edildi.\")\n",
    "    # Gerekirse GitHub'dan klonla veya dosyaları yükle\n",
    "    # !git clone https://github.com/your-repo/V-RAG.git\n",
    "    # %cd V-RAG\n",
    "else:\n",
    "    print(\"Lokal ortam tespit edildi.\")\n",
    "    # Proje kök dizinine git\n",
    "    if not os.path.exists('src'):\n",
    "        os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kütüphaneleri kur\n",
    "!pip install -q pymilvus==2.4.0 milvus-lite==2.4.0\n",
    "!pip install -q sentence-transformers==2.3.1\n",
    "!pip install -q transformers==4.36.2 torch==2.1.2\n",
    "!pip install -q nltk==3.8.1 tiktoken==0.5.2\n",
    "!pip install -q rouge-score==0.1.2 sacrebleu==2.3.1\n",
    "!pip install -q pandas numpy requests tqdm\n",
    "!pip install -q accelerate bitsandbytes\n",
    "\n",
    "print(\"Kütüphaneler kuruldu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gerekli Modülleri İçe Aktar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from chunker import HierarchicalChunker\n",
    "from vector_store import VectorStore\n",
    "from rag_pipeline import RAGPipeline\n",
    "from baseline_model import BaselineModel\n",
    "from metrics import MetricsEvaluator\n",
    "from experiment_runner import ExperimentRunner\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import torch\n",
    "\n",
    "print(\"Modüller yüklendi!\")\n",
    "print(f\"GPU kullanılabilir: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Veri Hazırlama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Kitap ve Soruları İndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader oluştur ve verileri indir\n",
    "loader = DataLoader(data_dir=\"data\")\n",
    "data_paths = loader.load_all_data()\n",
    "\n",
    "print(\"\\nİndirilen dosyalar:\")\n",
    "for key, path in data_paths.items():\n",
    "    print(f\"  {key}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test Verilerini İncele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorularını yükle\n",
    "test_df = pd.read_csv(data_paths['test'])\n",
    "\n",
    "print(f\"Toplam test sorusu: {len(test_df)}\")\n",
    "print(\"\\nİlk 3 soru:\")\n",
    "print(test_df[['question', 'answer1', 'answer2']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Hiyerarşik Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Chunker Oluştur ve Metni Parçala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kitap metnini yükle\n",
    "with open(data_paths['book'], 'r', encoding='utf-8') as f:\n",
    "    book_text = f.read()\n",
    "\n",
    "print(f\"Kitap uzunluğu: {len(book_text)} karakter\")\n",
    "\n",
    "# Chunker oluştur (Parent: 512, Child: 256, Overlap: 50)\n",
    "chunker = HierarchicalChunker(\n",
    "    parent_size=512,\n",
    "    child_size=256,\n",
    "    overlap=50\n",
    ")\n",
    "\n",
    "# Metni parçala\n",
    "parent_chunks, child_chunks = chunker.chunk_text(book_text)\n",
    "\n",
    "# İstatistikler\n",
    "stats = chunker.get_chunk_stats(parent_chunks, child_chunks)\n",
    "print(\"\\nChunk İstatistikleri:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value:.1f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Chunk Örneklerini Görüntüle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir parent chunk ve onun child'larını göster\n",
    "sample_parent = parent_chunks[0]\n",
    "sample_children = [c for c in child_chunks if c['parent_id'] == sample_parent['id']]\n",
    "\n",
    "print(\"Örnek Parent Chunk:\")\n",
    "print(f\"ID: {sample_parent['id']}\")\n",
    "print(f\"Token sayısı: {sample_parent['token_count']}\")\n",
    "print(f\"Metin (ilk 200 karakter): {sample_parent['text'][:200]}...\")\n",
    "\n",
    "print(\"\\nBu parent'ın child chunk'ları:\")\n",
    "for child in sample_children:\n",
    "    print(f\"  - {child['id']}: {child['token_count']} token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Vector Store ve Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Milvus Lite Vector Store Oluştur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store oluştur\n",
    "vector_store = VectorStore(\n",
    "    db_path=\"./milvus_rag.db\",\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Collection'ları oluştur\n",
    "vector_store.create_collections()\n",
    "\n",
    "print(f\"Embedding boyutu: {vector_store.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Chunk'ları İndeksle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Parent chunk'ları ekle\n",
    "start = time.time()\n",
    "vector_store.insert_parent_chunks(parent_chunks)\n",
    "parent_time = time.time() - start\n",
    "\n",
    "# Child chunk'ları ekle\n",
    "start = time.time()\n",
    "vector_store.insert_child_chunks(child_chunks)\n",
    "child_time = time.time() - start\n",
    "\n",
    "print(f\"\\nParent indexing süresi: {parent_time:.2f}s\")\n",
    "print(f\"Child indexing süresi: {child_time:.2f}s\")\n",
    "print(f\"Toplam indexing süresi: {parent_time + child_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Retrieval Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorusu ile retrieval dene\n",
    "test_query = \"Who are Zuleika's most prominent suitors?\"\n",
    "\n",
    "parent_results, child_results = vector_store.hybrid_search(\n",
    "    query=test_query,\n",
    "    top_parents=3,\n",
    "    top_children=5\n",
    ")\n",
    "\n",
    "print(f\"Test sorusu: {test_query}\")\n",
    "print(f\"\\nBulunan {len(child_results)} child chunk:\")\n",
    "for i, result in enumerate(child_results[:3], 1):\n",
    "    print(f\"\\n{i}. Score: {result['score']:.4f}\")\n",
    "    print(f\"   Metin: {result['text'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Baseline Model (RAG'sız)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Baseline Model Oluştur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model oluştur\n",
    "baseline = BaselineModel(model_name=\"google/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Baseline ile Test Sorularını Cevapla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorularını al\n",
    "questions = test_df['question'].tolist()\n",
    "\n",
    "# Baseline ile cevapla\n",
    "print(\"Baseline model ile sorular cevaplanıyor...\")\n",
    "baseline_results = baseline.batch_answer_questions(questions, max_new_tokens=100)\n",
    "\n",
    "print(f\"\\n{len(baseline_results)} soru cevaplandı!\")\n",
    "\n",
    "# İlk 3 cevabı göster\n",
    "print(\"\\nÖrnek Baseline Cevaplar:\")\n",
    "for i, result in enumerate(baseline_results[:3], 1):\n",
    "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
    "    print(f\"   Cevap: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 RAG Pipeline Oluştur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG pipeline oluştur\n",
    "rag_pipeline = RAGPipeline(\n",
    "    vector_store=vector_store,\n",
    "    model_name=\"google/gemma-2-2b-it\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 RAG ile Test Sorularını Cevapla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ile cevapla\n",
    "print(\"RAG pipeline ile sorular cevaplanıyor...\")\n",
    "rag_results = rag_pipeline.batch_answer_questions(\n",
    "    questions,\n",
    "    top_k_children=5,\n",
    "    max_new_tokens=100\n",
    ")\n",
    "\n",
    "print(f\"\\n{len(rag_results)} soru cevaplandı!\")\n",
    "\n",
    "# İlk 3 cevabı göster\n",
    "print(\"\\nÖrnek RAG Cevaplar:\")\n",
    "for i, result in enumerate(rag_results[:3], 1):\n",
    "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
    "    print(f\"   Cevap: {result['answer']}\")\n",
    "    print(f\"   Context (ilk 100 karakter): {result['context'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Performans Değerlendirme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 BLEU ve ROUGE Metrikleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics evaluator oluştur\n",
    "evaluator = MetricsEvaluator()\n",
    "\n",
    "# RAG vs Baseline karşılaştır\n",
    "comparison = evaluator.compare_models(\n",
    "    rag_results=rag_results,\n",
    "    baseline_results=baseline_results,\n",
    "    ground_truth=test_df\n",
    ")\n",
    "\n",
    "# Sonuçları yazdır\n",
    "evaluator.print_comparison(comparison)\n",
    "\n",
    "# Sonuçları kaydet\n",
    "evaluator.save_results(comparison, \"results/rag_vs_baseline.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Sonuçları Görselleştir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Karşılaştırma grafiği\n",
    "metrics = ['bleu', 'rouge1', 'rouge2', 'rougeL']\n",
    "rag_scores = [comparison['rag'][m] for m in metrics]\n",
    "baseline_scores = [comparison['baseline'][m] for m in metrics]\n",
    "\n",
    "x = range(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar([i - width/2 for i in x], rag_scores, width, label='RAG', color='#2ecc71')\n",
    "ax.bar([i + width/2 for i in x], baseline_scores, width, label='Baseline', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Metrikler', fontsize=12)\n",
    "ax.set_ylabel('Skor', fontsize=12)\n",
    "ax.set_title('RAG vs Baseline Performans Karşılaştırması', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([m.upper() for m in metrics])\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/rag_vs_baseline.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafik kaydedildi: results/rag_vs_baseline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Hiperparametre Optimizasyonu (Opsiyonel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Grid Search Hazırlığı\n",
    "\n",
    "**UYARI:** Bu bölüm çok uzun sürer (60 deney × ~5-10 dakika = ~5-10 saat).\n",
    "Sadece küçük bir subset ile test edin veya Colab Pro ile çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search parametreleri\n",
    "CHUNK_SIZES = [128, 256, 512]\n",
    "OVERLAPS = [0, 25, 50, 100]\n",
    "TEMPERATURES = [0.1, 0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "total_experiments = len(CHUNK_SIZES) * len(OVERLAPS) * len(TEMPERATURES)\n",
    "print(f\"Toplam deney sayısı: {total_experiments}\")\n",
    "print(f\"Tahmini süre: {total_experiments * 5} - {total_experiments * 10} dakika\")\n",
    "print(\"\\nDikkat: Bu uzun sürecektir! Küçük bir subset ile test etmeyi düşünün.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Grid Search Çalıştır (Küçük Subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Küçük bir subset ile test\n",
    "CHUNK_SIZES_SUBSET = [256, 512]\n",
    "OVERLAPS_SUBSET = [25, 50]\n",
    "TEMPERATURES_SUBSET = [0.1, 0.4]\n",
    "\n",
    "# Experiment runner oluştur\n",
    "runner = ExperimentRunner(\n",
    "    book_path=data_paths['book'],\n",
    "    test_questions_path=data_paths['test'],\n",
    "    results_dir=\"results/experiments\"\n",
    ")\n",
    "\n",
    "# Grid search çalıştır\n",
    "print(\"Grid search başlatılıyor (subset)...\")\n",
    "all_results = runner.run_grid_search(\n",
    "    chunk_sizes=CHUNK_SIZES_SUBSET,\n",
    "    overlaps=OVERLAPS_SUBSET,\n",
    "    temperatures=TEMPERATURES_SUBSET\n",
    ")\n",
    "\n",
    "# Sonuçları kaydet\n",
    "runner.save_summary(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Experiment Sonuçlarını Analiz Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları yükle\n",
    "exp_df = pd.read_csv('results/experiments/experiment_summary.csv')\n",
    "\n",
    "print(\"Experiment Özeti:\")\n",
    "print(exp_df[['child_size', 'overlap', 'temperature', 'bleu', 'rouge1', 'rougeL', 'total_time']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 En İyi Parametreleri Bul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU'ya göre sırala\n",
    "best_bleu = exp_df.nlargest(5, 'bleu')[['child_size', 'overlap', 'temperature', 'bleu', 'total_time']]\n",
    "print(\"En Yüksek BLEU Skorları:\")\n",
    "print(best_bleu)\n",
    "\n",
    "# ROUGE-L'ye göre sırala\n",
    "best_rougeL = exp_df.nlargest(5, 'rougeL')[['child_size', 'overlap', 'temperature', 'rougeL', 'total_time']]\n",
    "print(\"\\nEn Yüksek ROUGE-L Skorları:\")\n",
    "print(best_rougeL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Parametre Etkilerini Görselleştir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk size etkisi\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Chunk size vs BLEU\n",
    "exp_df.groupby('child_size')['bleu'].mean().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Chunk Size vs BLEU')\n",
    "axes[0].set_xlabel('Child Chunk Size')\n",
    "axes[0].set_ylabel('Ortalama BLEU')\n",
    "\n",
    "# Overlap vs ROUGE-L\n",
    "exp_df.groupby('overlap')['rougeL'].mean().plot(kind='bar', ax=axes[1], color='lightcoral')\n",
    "axes[1].set_title('Overlap vs ROUGE-L')\n",
    "axes[1].set_xlabel('Overlap')\n",
    "axes[1].set_ylabel('Ortalama ROUGE-L')\n",
    "\n",
    "# Temperature vs ROUGE-1\n",
    "exp_df.groupby('temperature')['rouge1'].mean().plot(kind='bar', ax=axes[2], color='lightgreen')\n",
    "axes[2].set_title('Temperature vs ROUGE-1')\n",
    "axes[2].set_xlabel('Temperature')\n",
    "axes[2].set_ylabel('Ortalama ROUGE-1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/parameter_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafik kaydedildi: results/parameter_effects.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Kaynak Kullanımı Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Memory ve Time Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(exp_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Memory kullanımı\n",
    "    exp_df.plot(x='child_size', y='memory_used_mb', kind='scatter', ax=axes[0], s=100, alpha=0.6)\n",
    "    axes[0].set_title('Chunk Size vs Memory Kullanımı')\n",
    "    axes[0].set_xlabel('Child Chunk Size')\n",
    "    axes[0].set_ylabel('Memory (MB)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Execution time\n",
    "    exp_df.plot(x='child_size', y='total_time', kind='scatter', ax=axes[1], s=100, alpha=0.6, color='orange')\n",
    "    axes[1].set_title('Chunk Size vs Toplam Süre')\n",
    "    axes[1].set_xlabel('Child Chunk Size')\n",
    "    axes[1].set_ylabel('Süre (saniye)')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/resource_usage.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Grafik kaydedildi: results/resource_usage.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Database Boyutu Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(exp_df) > 0:\n",
    "    # DB boyutlarını göster\n",
    "    db_stats = exp_df.groupby('child_size')['db_size_mb'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    db_stats.plot(kind='bar', color='purple', alpha=0.7)\n",
    "    plt.title('Ortalama Vector DB Boyutu')\n",
    "    plt.xlabel('Child Chunk Size')\n",
    "    plt.ylabel('DB Boyutu (MB)')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/db_size.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Grafik kaydedildi: results/db_size.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Sonuç ve Gözlemler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Ana Bulgular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PROJE ÖZETI VE BULGULAR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. RAG vs Baseline Performansı:\")\n",
    "print(f\"   - RAG BLEU: {comparison['rag']['bleu']:.2f}\")\n",
    "print(f\"   - Baseline BLEU: {comparison['baseline']['bleu']:.2f}\")\n",
    "print(f\"   - İyileştirme: {comparison['improvement']['bleu']:+.2f}\")\n",
    "\n",
    "if len(exp_df) > 0:\n",
    "    print(\"\\n2. En İyi Parametre Kombinasyonu:\")\n",
    "    best = exp_df.loc[exp_df['bleu'].idxmax()]\n",
    "    print(f\"   - Chunk Size: {best['child_size']}\")\n",
    "    print(f\"   - Overlap: {best['overlap']}\")\n",
    "    print(f\"   - Temperature: {best['temperature']}\")\n",
    "    print(f\"   - BLEU: {best['bleu']:.2f}\")\n",
    "\n",
    "print(\"\\n3. Kaynak Kullanımı:\")\n",
    "print(f\"   - Ortalama indexing süresi: {(parent_time + child_time):.2f}s\")\n",
    "print(f\"   - GPU kullanımı: {'Evet' if torch.cuda.is_available() else 'Hayır'}\")\n",
    "\n",
    "print(\"\\n4. Zorluklar ve Gözlemler:\")\n",
    "print(\"   - Google Colab kaynak kısıtları nedeniyle grid search uzun sürdü\")\n",
    "print(\"   - Hiyerarşik chunking, context kalitesini artırdı\")\n",
    "print(\"   - Optimal chunk size ve overlap değerleri veri setine bağlı\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Tüm Sonuçları Dışa Aktar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm sonuçları bir yerde topla\n",
    "final_report = {\n",
    "    'project_info': {\n",
    "        'book': 'Zuleika Dobson by Max Beerbohm',\n",
    "        'dataset': 'NarrativeQA',\n",
    "        'test_questions': len(test_df),\n",
    "        'vector_db': 'Milvus Lite',\n",
    "        'embedding_model': 'all-MiniLM-L6-v2',\n",
    "        'llm': 'google/gemma-2-2b-it'\n",
    "    },\n",
    "    'chunk_stats': stats,\n",
    "    'rag_vs_baseline': comparison,\n",
    "    'best_config': exp_df.loc[exp_df['bleu'].idxmax()].to_dict() if len(exp_df) > 0 else None\n",
    "}\n",
    "\n",
    "# JSON olarak kaydet\n",
    "with open('results/final_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Final rapor kaydedildi: results/final_report.json\")\n",
    "print(\"\\nProje tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notlar ve İyileştirme Önerileri\n",
    "\n",
    "### Gözlemler:\n",
    "1. **Hiyerarşik Chunking:** Parent-child yapısı, hem geniş context hem de detaylı bilgi sağladı\n",
    "2. **Milvus Lite:** Disk-based yapısı Colab için ideal, memory kullanımı düşük\n",
    "3. **Hyperparameter Tuning:** Chunk size, overlap ve temperature'ün kombinasyonu performansı etkiliyor\n",
    "\n",
    "### İyileştirme Önerileri:\n",
    "1. Reranking mekanizması eklenebilir (Cross-encoder)\n",
    "2. Query expansion ile retrieval kalitesi artırılabilir\n",
    "3. Daha büyük LLM'ler (7B, 13B) test edilebilir\n",
    "4. Multi-hop reasoning için iterative retrieval denenebilir\n",
    "\n",
    "### Colab Kullanım Tavsiyeleri:\n",
    "- GPU runtime kullanın (Runtime → Change runtime type → GPU)\n",
    "- Uzun süren işlemler için Colab Pro düşünün\n",
    "- Checkpoint'ler kaydedin (disconnect olursa devam edebilmek için)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
