{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOdTxV3ph9aa"
      },
      "source": [
        "# Hierarchical RAG System for Zuleika Dobson\n",
        "\n",
        "Bu notebook, Project Gutenberg'den \"Zuleika Dobson\" kitabƒ±nƒ± kullanarak hiyerar≈üik par√ßalama y√∂ntemiyle bir RAG (Retrieval-Augmented Generation) sistemi olu≈üturur.\n",
        "\n",
        "**Proje Detaylarƒ±:**\n",
        "- **Kitap:** Zuleika Dobson by Max Beerbohm\n",
        "- **Dataset:** NarrativeQA (ƒ∞lgili kitap i√ßin 40 test sorusu)\n",
        "- **Vector DB:** Milvus Lite tercih ettim\n",
        "- **Embedding Model:** all-MiniLM-L6-v2\n",
        "- **LLM:** google/gemma-3-1b-it\n",
        "- **Metrikler:** BLEU, ROUGE-1, ROUGE-2, ROUGE-L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB7aTLVNh9ac"
      },
      "source": [
        "---\n",
        "## 1. Kurulum ve Hazƒ±rlƒ±k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01oXF_MKh9ac"
      },
      "source": [
        "### 1.1 Git Repo & K√ºt√ºphaneler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbOETlmNh9ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45752cbd-0748-43ae-8689-96cfb5390f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/V-RAG\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 12 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 51.41 KiB | 223.00 KiB/s, done.\n",
            "From https://github.com/sendayildirim/V-RAG\n",
            "   378a291..f7c6d83  main       -> origin/main\n",
            "Updating 378a291..f7c6d83\n",
            "Fast-forward\n",
            " notebooks/main_rag_notebook.ipynb | 8165 \u001b[32m++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " src/experiment_runner.py          |    2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/rag_pipeline.py               |    2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 3 files changed, 8109 insertions(+), 60 deletions(-)\n",
            "proje y√ºklendi\n",
            "data\t milvus_c50_o0.db   milvus_c50_o50.db  notebooks  requirements.txt  src\n",
            "LICENSE  milvus_c50_o25.db  milvus_rag.db      README.md  results\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if not os.path.exists('V-RAG'):\n",
        "    !git clone https://github.com/sendayildirim/V-RAG\n",
        "    %cd V-RAG\n",
        "else:\n",
        "    %cd V-RAG\n",
        "    !git pull\n",
        "\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "print(\"proje y√ºklendi\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n"
      ],
      "metadata": {
        "id": "i8z_sTQjnZ1t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dh2Uddoh9ae"
      },
      "source": [
        "### 1.2 Gerekli Mod√ºlleri ƒ∞√ße Aktar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7KWI5gjNh9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b0a3ab-73da-4372-c4d0-29d7d44ebda2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mod√ºller y√ºklendi!\n",
            "GPU kullanƒ±labilme durumu: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from data_loader import DataLoader\n",
        "from chunker import HierarchicalChunker\n",
        "from vector_store import VectorStore\n",
        "from rag_pipeline import RAGPipeline\n",
        "from baseline_model import BaselineModel\n",
        "from metrics import MetricsEvaluator\n",
        "from experiment_runner import ExperimentRunner\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import torch\n",
        "\n",
        "##Cobal Runtime alanƒ±ndan Hardware accelerator'ƒ± NVIDIA A100-SXM4-40GB olarak deƒüi≈ütirdim. (pro √ºyeliƒüim var olduƒüundan)\n",
        "\n",
        "print(\"mod√ºller y√ºklendi!\")\n",
        "print(f\"GPU kullanƒ±labilme durumu: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YOkP4EIh9ae"
      },
      "source": [
        "---\n",
        "## 2. Veri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wULKTPAUh9af"
      },
      "source": [
        "### 2.1 Kitap ve Sorular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LEwrKS6Fh9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f70a142-a2c8-4436-abac-2a96e59c704e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kitap indiriliyor...\n",
            "Kitap kaydedildi: data/zuleika_dobson.txt\n",
            "Sorular indiriliyor...\n",
            "\n",
            "Toplam 40 soru bulundu\n",
            "Test: 40\n",
            "\n",
            "Sorular kaydedildi:\n",
            "  Test: data/questions_test.csv\n",
            "\n",
            "ƒ∞ndirilen dosyalar:\n",
            "  book: data/zuleika_dobson.txt\n",
            "  test: data/questions_test.csv\n"
          ]
        }
      ],
      "source": [
        "# Data loader olu≈ütur ve verileri indir\n",
        "loader = DataLoader(data_dir=\"data\")\n",
        "data_paths = loader.load_all_data()\n",
        "\n",
        "print(\"\\nƒ∞ndirilen dosyalar:\")\n",
        "print(f\"  book: {data_paths['book']}\")\n",
        "print(f\"  test: {data_paths['test']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbx6Abuxh9af"
      },
      "source": [
        "### 2.2 Test Verisi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lryey0PXh9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed9b3ec-7b5f-4114-b340-5ac6367a873e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam test sorusu: 40\n",
            "\n",
            "ƒ∞lk 3 soru:\n",
            "                                            question  \\\n",
            "0          Who are Zuleika's most prominent suitors?   \n",
            "1                  Why does Zuleika reject the Duke?   \n",
            "2  Who is the first person Zuleika falls in love ...   \n",
            "\n",
            "                                             answer1  \\\n",
            "0                       The Duke of Dorset and Noaks   \n",
            "1  She claims she can only love someone who is im...   \n",
            "2                                 The Duke of Dorset   \n",
            "\n",
            "                               answer2  \n",
            "0             Duke of Dorset and Noaks  \n",
            "1  She felt he was too charmed by her.  \n",
            "2             With the Duke of Dorset.  \n"
          ]
        }
      ],
      "source": [
        "# Test sorularƒ±nƒ± y√ºkle\n",
        "test_df = pd.read_csv(data_paths['test'])\n",
        "\n",
        "print(f\"Toplam test sorusu: {len(test_df)}\")\n",
        "print(\"\\nƒ∞lk 3 soru:\")\n",
        "print(test_df[['question', 'answer1', 'answer2']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFDeB0U3h9af"
      },
      "source": [
        "---\n",
        "## 3. Hiyerar≈üik Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlSpOei6h9af"
      },
      "source": [
        "### 3.1 Chunker olu≈üturma ve metni par√ßalama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B1XTXWQbh9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da041de7-beb0-4052-b832-b4c7968298d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kitap uzunluƒüu: 467638 karakter\n",
            "Toplam 245 parent chunk olusturuldu\n",
            "Toplam 734 child chunk olusturuldu\n",
            "\n",
            "Chunk ƒ∞statistikleri:\n",
            "  parent_count: 245\n",
            "  child_count: 734\n",
            "  parent_avg_tokens: 511.1\n",
            "  child_avg_tokens: 187.3\n",
            "  parent_max_tokens: 512\n",
            "  child_max_tokens: 256\n"
          ]
        }
      ],
      "source": [
        "# Kitap metnini y√ºkle\n",
        "with open(data_paths['book'], 'r', encoding='utf-8') as f:\n",
        "    book_text = f.read()\n",
        "\n",
        "print(f\"Kitap uzunluƒüu: {len(book_text)} karakter\")\n",
        "\n",
        "# Chunker olu≈ütur (Parent: 512, Child: 256, Overlap: 50)\n",
        "chunker = HierarchicalChunker(\n",
        "    parent_size=512,\n",
        "    child_size=256,\n",
        "    overlap=50\n",
        ")\n",
        "\n",
        "# Metni par√ßala\n",
        "parent_chunks, child_chunks = chunker.chunk_text(book_text)\n",
        "\n",
        "# ƒ∞statistikler\n",
        "stats = chunker.get_chunk_stats(parent_chunks, child_chunks)\n",
        "print(\"\\nChunk ƒ∞statistikleri:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"  {key}: {value:.1f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqjZQA81h9ag"
      },
      "source": [
        "### 3.2 Chunk √ñrnekleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OPaqZarih9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369edb5e-e52c-4c44-b58f-78e3fed9ec6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "√ñrnek Parent Chunk:\n",
            "ID: parent_0\n",
            "Token sayƒ±sƒ±: 512\n",
            "Metin (ilk 200 karakter): Produced by Judy Boss\n",
            "\n",
            "ZULEIKA DOBSON\n",
            "\n",
            "or, AN OXFORD LOVE STORY\n",
            "\n",
            "By Max Beerbohm\n",
            "\n",
            " NOTE to the 1922 edition\n",
            "\n",
            " I was in Italy when this book was first published.\n",
            " A year later (1912) I visited London, ...\n",
            "\n",
            "Bu parent'ƒ±n child chunk'larƒ±:\n",
            "  - child_0_0: 256 token\n",
            "  - child_0_1: 256 token\n",
            "  - child_0_2: 50 token\n"
          ]
        }
      ],
      "source": [
        "# Bir parent chunk ve onun child'larƒ±nƒ± g√∂ster\n",
        "sample_parent = parent_chunks[0]\n",
        "sample_children = [c for c in child_chunks if c['parent_id'] == sample_parent['id']]\n",
        "\n",
        "print(\"√ñrnek Parent Chunk:\")\n",
        "print(f\"ID: {sample_parent['id']}\")\n",
        "print(f\"Token sayƒ±sƒ±: {sample_parent['token_count']}\")\n",
        "print(f\"Metin (ilk 200 karakter): {sample_parent['text'][:200]}...\")\n",
        "\n",
        "print(\"\\nBu parent'ƒ±n child chunk'larƒ±:\")\n",
        "for child in sample_children:\n",
        "    print(f\"  - {child['id']}: {child['token_count']} token\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYyjC5Zmh9ag"
      },
      "source": [
        "---\n",
        "## 4. Vector Store ve Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yl9Wzhlh9ag"
      },
      "source": [
        "### 4.1 Milvus Lite Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UmUzZwHkh9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa085138-61da-45ab-cf1e-9c50891affcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding modeli yukleniyor: all-mpnet-base-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection'lar olusturuldu: parent_chunks, child_chunks\n",
            "Embedding boyutu: 768\n"
          ]
        }
      ],
      "source": [
        "# Vector store olu≈ütur\n",
        "vector_store = VectorStore(\n",
        "    db_path=\"./milvus_rag.db\",\n",
        "    model_name=\"all-mpnet-base-v2\"  #\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# Collection'larƒ± olu≈ütur\n",
        "vector_store.create_collections()\n",
        "\n",
        "print(f\"Embedding boyutu: {vector_store.embedding_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHiYxOShh9ag"
      },
      "source": [
        "### 4.2 Chunk'larƒ± indeksleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k9yzyv2Rh9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ff1423-5acc-44d2-83ed-22be88dba70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "245 parent chunk eklendi\n",
            "734 child chunk eklendi\n",
            "\n",
            "Parent indexing s√ºresi: 1.79s\n",
            "Child indexing s√ºresi: 2.63s\n",
            "Toplam indexing s√ºresi: 4.42s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Parent chunk'larƒ± ekle\n",
        "start = time.time()\n",
        "vector_store.insert_parent_chunks(parent_chunks)\n",
        "parent_time = time.time() - start\n",
        "\n",
        "# Child chunk'larƒ± ekle\n",
        "start = time.time()\n",
        "vector_store.insert_child_chunks(child_chunks)\n",
        "child_time = time.time() - start\n",
        "\n",
        "print(f\"\\nParent indexing s√ºresi: {parent_time:.2f}s\")\n",
        "print(f\"Child indexing s√ºresi: {child_time:.2f}s\")\n",
        "print(f\"Toplam indexing s√ºresi: {parent_time + child_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqWxDBhxh9ag"
      },
      "source": [
        "### 4.3 Retrieval Testi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gj3vGy0jh9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf18714-0ee6-443c-c2ca-3dfa89d9c5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sorusu: Who are Zuleika's most prominent suitors?\n",
            "\n",
            "Bulunan 5 child chunk:\n",
            "\n",
            "1. Score: 0.6128\n",
            "   Metin:  sanguine aversion. She could love none but a youth. Nor--though\n",
            "she herself, womanly, would utterly abase herself before her\n",
            "ideal--could she love on...\n",
            "\n",
            "2. Score: 0.6126\n",
            "   Metin:  reflects.\n",
            "\n",
            "Zuleika was not strictly beautiful. Her eyes were a trifle large, and\n",
            "their lashes longer than they need have been. An anarchy of small cu...\n",
            "\n",
            "3. Score: 0.6042\n",
            "   Metin:  reflects.\n",
            "\n",
            "Zuleika was not strictly beautiful. Her eyes were a trifle large, and\n",
            "their lashes longer than they need have been. An anarchy of small cu...\n"
          ]
        }
      ],
      "source": [
        "# Test sorusu ile retrieval dene\n",
        "test_query = \"Who are Zuleika's most prominent suitors?\"\n",
        "\n",
        "parent_results, child_results = vector_store.hybrid_search(\n",
        "    query=test_query,\n",
        "    top_parents=3,\n",
        "    top_children=5\n",
        ")\n",
        "\n",
        "print(f\"Test sorusu: {test_query}\")\n",
        "print(f\"\\nBulunan {len(child_results)} child chunk:\")\n",
        "for i, result in enumerate(child_results[:3], 1):\n",
        "    print(f\"\\n{i}. Score: {result['score']:.4f}\")\n",
        "    print(f\"   Metin: {result['text'][:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlZeDg58h9ag"
      },
      "source": [
        "---\n",
        "## 5. Baseline Model (RAG'sƒ±z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF_XrtIjh9ag"
      },
      "source": [
        "### 5.1 Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ],
      "metadata": {
        "id": "qEhLYqc2x20m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZSIV25vzh9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be937fe8-2184-44ce-cb01-a1e29a54838e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cihaz: cuda\n",
            "Baseline model yukleniyor: google/gemma-3-1b-it\n",
            "Baseline model yuklendi!\n"
          ]
        }
      ],
      "source": [
        "# Baseline model olu≈ütur\n",
        "baseline = BaselineModel(model_name=\"google/gemma-3-1b-it\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p980w-Kh9ag"
      },
      "source": [
        "### 5.2 Baseline ile Test Sorularƒ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bbr2dLS9h9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4da49c3-7248-447e-db37-2b24cd0dd01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model ile sorular cevaplanƒ±yor...\n",
            "\n",
            "Soru 1/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 2/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 3/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 4/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 5/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 6/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 7/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 8/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 9/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 10/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 11/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 12/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 13/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 14/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 15/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 16/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 17/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 18/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 19/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 20/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 21/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 22/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 23/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 24/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 25/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 26/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 27/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 28/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 29/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 30/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 31/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 32/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 33/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 34/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 35/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 36/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 37/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 38/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 39/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 40/40 cevaplanƒ±yor...\n",
            "\n",
            "40 soru cevaplandƒ±!\n",
            "\n",
            "√ñrnek Baseline Cevaplar:\n",
            "\n",
            "1. Soru: Who are Zuleika's most prominent suitors?\n",
            "   Cevap: Zuleika Dobson‚Äôs most prominent suitors are **Charles, a wealthy, established gentleman, and Edward, a somewhat erratic and charming military man.**\n",
            "\n",
            "While she has a few other suitors throughout the novel, Charles and Edward represent the most significant and ultimately tragic connections she experiences. They represent different facets of her desires and the limitations of her social standing.\n",
            "\n",
            "2. Soru: Why does Zuleika reject the Duke?\n",
            "   Cevap: Zuleika rejects the Duke primarily because of his **lack of genuine affection and his manipulative nature.** She sees him as a shallow, self-absorbed man who prioritizes his own pleasure and social standing over anything truly meaningful. She feels he‚Äôs obsessed with appearances and uses her as a pawn in his own schemes. \n",
            "\n",
            "Here‚Äôs a slightly more detailed breakdown of her reasoning:\n",
            "\n",
            "* **He‚Äôs a \"fool\" and \"blind\":** She believes he‚Äôs incapable of understanding her feelings or appreciating her intelligence.\n",
            "* **He‚Äôs obsessed with her appearance:** She finds his preoccupation with her beauty and social status utterly repulsive.\n",
            "* **He‚Äôs a manipulator:** She perceives him as deliberately trying to control her and use her for his own gain. \n",
            "* **He‚Äôs fundamentally selfish:**  She sees him as driven by a desire for validation and attention, rather than genuine connection.\n",
            "\n",
            "\n",
            "Essentially, Zuleika rejects him because she believes he‚Äô\n",
            "\n",
            "3. Soru: Who is the first person Zuleika falls in love with?\n",
            "   Cevap: The first person Zuleika falls in love with is **Arthur, the police constable.**\n"
          ]
        }
      ],
      "source": [
        "# Test sorularƒ±nƒ± al\n",
        "questions = test_df['question'].tolist()\n",
        "\n",
        "# Baseline ile cevapla\n",
        "print(\"Baseline model ile sorular cevaplanƒ±yor...\")\n",
        "baseline_results = baseline.batch_answer_questions(questions, max_new_tokens=200)\n",
        "\n",
        "print(f\"\\n{len(baseline_results)} soru cevaplandƒ±!\")\n",
        "\n",
        "# ƒ∞lk 3 cevabƒ± g√∂ster\n",
        "print(\"\\n√ñrnek Baseline Cevaplar:\")\n",
        "for i, result in enumerate(baseline_results[:3], 1):\n",
        "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
        "    print(f\"   Cevap: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "id": "rwV4usqNWElv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3570d84-f304-40b5-8274-e95de8b4fb6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': \"Who are Zuleika's most prominent suitors?\",\n",
              "  'answer': 'Zuleika Dobson‚Äôs most prominent suitors are **Charles, a wealthy, established gentleman, and Edward, a somewhat erratic and charming military man.**\\n\\nWhile she has a few other suitors throughout the novel, Charles and Edward represent the most significant and ultimately tragic connections she experiences. They represent different facets of her desires and the limitations of her social standing.'},\n",
              " {'question': 'Why does Zuleika reject the Duke?',\n",
              "  'answer': 'Zuleika rejects the Duke primarily because of his **lack of genuine affection and his manipulative nature.** She sees him as a shallow, self-absorbed man who prioritizes his own pleasure and social standing over anything truly meaningful. She feels he‚Äôs obsessed with appearances and uses her as a pawn in his own schemes. \\n\\nHere‚Äôs a slightly more detailed breakdown of her reasoning:\\n\\n* **He‚Äôs a \"fool\" and \"blind\":** She believes he‚Äôs incapable of understanding her feelings or appreciating her intelligence.\\n* **He‚Äôs obsessed with her appearance:** She finds his preoccupation with her beauty and social status utterly repulsive.\\n* **He‚Äôs a manipulator:** She perceives him as deliberately trying to control her and use her for his own gain. \\n* **He‚Äôs fundamentally selfish:**  She sees him as driven by a desire for validation and attention, rather than genuine connection.\\n\\n\\nEssentially, Zuleika rejects him because she believes he‚Äô'},\n",
              " {'question': 'Who is the first person Zuleika falls in love with?',\n",
              "  'answer': 'The first person Zuleika falls in love with is **Arthur, the police constable.**'},\n",
              " {'question': 'Where do Zuleika and her suitors meet?',\n",
              "  'answer': 'Zuleika and her suitors meet primarily in the **local pub, The King‚Äôs Head**, in the small coastal town of Port Blossom.'},\n",
              " {'question': \"How does Zuleika stop the Duke's first suicide attempt?\",\n",
              "  'answer': 'The answer is: **Zuleika, driven by a desperate, almost frantic, desire to protect her own life, physically pushes the Duke away from her, causing him to stumble and fall into the fireplace.**\\n\\nIt‚Äôs a surprisingly violent and shocking climax that ultimately stops his planned suicide.'},\n",
              " {'question': \"How many people eventually commit suicide on Zuleika's behalf?\",\n",
              "  'answer': 'The answer is **three**.\\n\\nZuleika Dobson commits suicide by shooting herself in the chest. Her brother, Herbert, and her fianc√©, Charles, both take their lives.'},\n",
              " {'question': 'Where does the Duke eventually die, and what is he wearing?',\n",
              "  'answer': 'The Duke eventually dies in a carriage, driving towards the coast. He is wearing a dark coat and a hat.'},\n",
              " {'question': 'What is the omen that indicates a Duke of Dorset is about to die?',\n",
              "  'answer': 'The omen that indicates a Duke of Dorset is about to die is a **black crow**.'},\n",
              " {'question': \"Who is Zuleika's grandfather?\",\n",
              "  'answer': 'Zuleika Dobson‚Äôs grandfather is named **Mr. Dobson**.'},\n",
              " {'question': 'Where does Zuleika go at the end of this series of events?',\n",
              "  'answer': 'Zuleika goes to **the island of Santa Maria in the Azores**. \\n\\nIt‚Äôs a pivotal and deeply symbolic ending, marking a complete shift in her life and a final, unsettling acceptance of her fate.'},\n",
              " {'question': 'Where does Zuleika attend school?',\n",
              "  'answer': 'Zuleika attends school at **The Academy**.'},\n",
              " {'question': 'Who was the first female admitted to Oxford University?',\n",
              "  'answer': 'This is a trick question! The first female admitted to Oxford University was **Elizabeth Fry**. \\n\\nIt‚Äôs a common misconception that the question is about the book, but it‚Äôs a completely unrelated historical fact. üòä'},\n",
              " {'question': \"Who is Zuleika's first love?\",\n",
              "  'answer': 'Zuleika‚Äôs first love is **Julian**.'},\n",
              " {'question': \"Who says he's going to commit suicide to symbolize his passion for Zuleika?\",\n",
              "  'answer': 'The character who says he‚Äôs going to commit suicide to symbolize his passion for Zuleika is **Mr. Finch**.'},\n",
              " {'question': \"Who interrupts the Duke's first suicide attempt?\",\n",
              "  'answer': 'The Duke interrupts Zuleika Dobson‚Äôs first suicide attempt.'},\n",
              " {'question': 'After many of the students have died how does Zuleika choose to travel away from Oxford?',\n",
              "  'answer': 'The answer is: **She chooses to travel to the coast of Cornwall.**\\n\\nHere‚Äôs a bit more detail about how this is revealed in the book:\\n\\nAfter the deaths of many of her classmates, Zuleika, driven by her grief and a desperate need to escape the suffocating atmosphere of Oxford, decides to travel to the coast of Cornwall. She intends to go to the lighthouse, hoping to find a moment of peace and solitude amidst the vastness of the sea.'},\n",
              " {'question': 'At the end of the story Zuleika is leaving Oxford and heading to where?',\n",
              "  'answer': 'Zuleika is leaving Oxford and heading to **the American West**.'},\n",
              " {'question': 'How many black owls are in this story?',\n",
              "  'answer': 'The story of \"Zuleika Dobson\" doesn‚Äôt explicitly state the number of black owls. It‚Äôs a key, unsettling detail that contributes to the atmosphere of dread and mystery, but the number is never given. It‚Äôs left deliberately ambiguous, adding to the unsettling feeling of the narrative.'},\n",
              " {'question': 'Where do the black owls perch all night long?',\n",
              "  'answer': 'The black owls perch all night long in the **kitchen**.'},\n",
              " {'question': 'What does Zuleika want the Duke to shout as he jumps into the river?',\n",
              "  'answer': 'Zuleika wants the Duke to shout, ‚Äú**I‚Äôm finished!**‚Äù'},\n",
              " {'question': 'In what era is Zuleika Dobson living?',\n",
              "  'answer': 'The book ‚ÄúZuleika Dobson‚Äù is set in the **1920s**. Specifically, it‚Äôs largely set in the early 1920s, with the events unfolding in the aftermath of the First World War and the burgeoning era of post-war disillusionment.'},\n",
              " {'question': \"What was Zuleika Dobson's profession before she became a prestidigitator?\",\n",
              "  'answer': 'The answer is that Zuleika Dobson was a **librarian**.'},\n",
              " {'question': 'Which university does Zuleika gain entrance to?',\n",
              "  'answer': 'Zuleika gains entrance to **Oxford University**.'},\n",
              " {'question': 'What happens while the Duke is drowning himself?',\n",
              "  'answer': 'The Duke is drowning himself while reading a letter to his wife. He‚Äôs completely absorbed in the letter, and the scene is described with a frantic, almost desperate, intensity. \\n\\nIt‚Äôs a very unsettling and detailed description, highlighting his isolation and the overwhelming nature of his grief.'},\n",
              " {'question': \"Where does the Duke of Dorset's first suicide attempt take place?\",\n",
              "  'answer': 'The Duke of Dorset‚Äôs first suicide attempt takes place in the **garden** of his estate.'},\n",
              " {'question': 'What does tradition say takes place the night before the death of a Duke of Dorset?',\n",
              "  'answer': 'The answer is: **The Duke of Dorset is poisoned.**\\n\\nThis is a key and famously revealed detail in the novel.'},\n",
              " {'question': 'How does the Duke decide to stop the undergraduates from committing suicide for love of Zuleika?',\n",
              "  'answer': 'The Duke, after a lengthy and somewhat unsettling conversation with Zuleika, decides to stop the undergraduates from committing suicide for love of her. He doesn‚Äôt simply issue a stern warning; instead, he proposes a series of increasingly bizarre and unsettling measures. Here‚Äôs a breakdown of his plan:\\n\\n* **The ‚ÄúGuardian‚Äù System:** He establishes a ‚ÄúGuardian‚Äù system, essentially a network of individuals tasked with monitoring and subtly influencing the students. These Guardians are not directly involved in the suicides themselves, but they are positioned to observe and intervene if necessary.\\n* **The ‚ÄúShadows‚Äù:** He introduces the concept of ‚ÄúShadows‚Äù ‚Äì individuals who are subtly connected to the students, appearing and disappearing at random, and seemingly offering assistance or guidance. These Shadows are incredibly unsettling and often seem to be manipulating the students‚Äô thoughts and feelings.\\n* **The ‚ÄúMirror‚Äù:** He commissions a mirror to be placed in the college chapel, designed to reflect the students‚Äô innermost thoughts'},\n",
              " {'question': 'Who sends the Duke a telegram?',\n",
              "  'answer': 'The Duke sends the telegram to the Duke.'},\n",
              " {'question': 'Where does Zulika go when she leaves Oxford?',\n",
              "  'answer': 'Zulika goes to **Paris**.'},\n",
              " {'question': 'What is the Duke wearing when he drowns himself in the River Isis?',\n",
              "  'answer': 'The Duke is wearing a **red waistcoat and a white shirt**. \\n\\nIt‚Äôs a very specific detail that‚Äôs crucial to the ending of the novel.'},\n",
              " {'question': 'Who is the protagonist of the story?',\n",
              "  'answer': 'The protagonist of ‚ÄúZuleika Dobson‚Äù is **Zuleika Dobson**.'},\n",
              " {'question': \"What is the name of Zuleika's current profession?\",\n",
              "  'answer': 'The answer is **‚Äúlibrarian‚Äù**.'},\n",
              " {'question': 'Which educational institution is Zuleika admitted to?',\n",
              "  'answer': 'Zuleika Dobson is admitted to **The University of London**.'},\n",
              " {'question': 'What physical characteristics set Zuleika apart from the other Oxford University students?',\n",
              "  'answer': 'The physical characteristics that set Zuleika Dobson apart from the other Oxford University students are strikingly unusual and contribute significantly to her character and the novel‚Äôs atmosphere. Here‚Äôs a breakdown:\\n\\n* **Pale Skin:** Her skin is incredibly pale, almost translucent, with a noticeable bluish tinge. This is the most prominent and defining feature.\\n* **Large, Dark Eyes:** Her eyes are large and dark, often described as ‚Äúblack‚Äù or ‚Äúdeep brown,‚Äù and they seem to hold a strange, unsettling intensity.\\n* **Small, Delicate Features:** She possesses a small, almost fragile appearance ‚Äì a delicate nose, a small mouth, and a generally understated beauty.\\n* **Unusual Hair:** Her hair is described as ‚Äúa shade of grey-green‚Äù and is often described as ‚Äúunusually thick and glossy.‚Äù\\n\\nThese physical traits aren‚Äôt just aesthetic; they‚Äôre deeply connected to her mental state and her perception of the world, reflecting a profound and unsettling isolation'},\n",
              " {'question': 'Who does Zuleika fall in with love while at school?',\n",
              "  'answer': 'Zuleika falls in love with **Mr. Davies**, the schoolmaster.'},\n",
              " {'question': \"Why does Zuleika reject the Duke of Dorset's marriage proposal?\",\n",
              "  'answer': 'Zuleika rejects the Duke of Dorset‚Äôs marriage proposal primarily because she believes he is a **manipulative and emotionally abusive partner.** \\n\\nHere‚Äôs a breakdown of the key reasons, as revealed throughout the novel:\\n\\n* **Her perception of his behavior:** She sees him as obsessed with her, constantly trying to control her and manipulating her feelings. He uses her vulnerabilities and insecurities against her.\\n* **His lack of genuine affection:** She feels he doesn‚Äôt truly love her, only enjoys her attention and uses her for his own gratification.\\n* **His controlling nature:** He‚Äôs insistent on her staying in the house, demanding her attention, and attempting to dictate her life.\\n* **Her growing disillusionment:**  She‚Äôs become increasingly convinced that he‚Äôs not a good man and that his intentions are purely selfish.\\n\\nEssentially, Zuleika rejects him because she recognizes he‚Äôs a deeply flawed and destructive figure, and she‚Äôs determined to protect'},\n",
              " {'question': 'What does the Duke of Dorset decide to do in order to incite Zuleika to accept accountability of her formidable powers?',\n",
              "  'answer': 'The Duke of Dorset decides to **force Zuleika to write a letter detailing her powers.** He wants to create a document that will solidify his position as the dominant figure in her life and, by extension, her power. He believes this will make her feel indebted and obligated to him, thereby encouraging her to accept responsibility for her abilities.'},\n",
              " {'question': 'Who initially prevents the Duke of Dorset from killing himself on his first suicide attempt?',\n",
              "  'answer': 'The initial prevention of the Duke of Dorset from killing himself is **Mrs. Higgins**.'},\n",
              " {'question': 'What omen does the butler of Tankerton Hall warn the Duke of Dorcet about?',\n",
              "  'answer': 'The butler of Tankerton Hall warns the Duke of Dorcet about a **‚Äúdark omen‚Äù**. \\n\\nIt‚Äôs a rather cryptic and unsettling phrase, hinting at a deeper, more sinister threat than simply a bad omen.'},\n",
              " {'question': 'Upon finding out that the entire Oxford University student body has now succumbed to suicide, where does Zuleika decide to go?',\n",
              "  'answer': 'Zuleika Dobson decides to go to **the Thames**.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_df = pd.DataFrame(baseline_results)\n",
        "\n",
        "os.makedirs(\"/content/V-RAG/results\", exist_ok=True)\n",
        "baseline_df.to_csv(\"/content/V-RAG/results/baseline_QA.csv\", index=False)"
      ],
      "metadata": {
        "id": "0GxKSkvTWtcA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6CaIeUUh9ag"
      },
      "source": [
        "---\n",
        "## 6. RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RMQEgoAh9ag"
      },
      "source": [
        "### 6.1 RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LqNratewh9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d106c1-6308-49cf-81c3-33eeb3f88744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cihaz: cuda\n",
            "Model yukleniyor: google/gemma-3-1b-it\n",
            "Model yuklendi!\n"
          ]
        }
      ],
      "source": [
        "# RAG pipeline olu≈ütur\n",
        "rag_pipeline = RAGPipeline(\n",
        "    vector_store=vector_store,\n",
        "    model_name=\"google/gemma-3-1b-it\",\n",
        "    temperature=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3stgbuh9ag"
      },
      "source": [
        "### 6.2 RAG ile Test Sorularƒ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NJkunDith9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472f37e7-b436-43af-e24c-e4602efd3dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG pipeline ile sorular cevaplanƒ±yor...\n",
            "\n",
            "Soru 1/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 2/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 3/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 4/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 5/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 6/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 7/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 8/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 9/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 10/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 11/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 12/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 13/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 14/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 15/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 16/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 17/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 18/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 19/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 20/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 21/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 22/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 23/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 24/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 25/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 26/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 27/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 28/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 29/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 30/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 31/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 32/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 33/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 34/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 35/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 36/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 37/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 38/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 39/40 cevaplanƒ±yor...\n",
            "\n",
            "Soru 40/40 cevaplanƒ±yor...\n",
            "\n",
            "40 soru cevaplandƒ±!\n",
            "\n",
            "√ñrnek RAG Cevaplar:\n",
            "\n",
            "1. Soru: Who are Zuleika's most prominent suitors?\n",
            "   Cevap: According to the text, Zuleika‚Äôs most prominent suitors are:\n",
            "\n",
            "*   The Statue of Liberty\n",
            "*   The Grand Duke Salamander\n",
            "*   The American Eagle\n",
            "*   Cupid‚Äôs bow\n",
            "*   Theodore Roosevelt\n",
            "*   Theodore Roosevelt‚Äôs Uncle Sam\n",
            "   Context (ilk 100 karakter): [1]  sanguine aversion. She could love none but a youth. Nor--though\n",
            "she herself, womanly, would utt...\n",
            "\n",
            "2. Soru: Why does Zuleika reject the Duke?\n",
            "   Cevap: Zuleika rejects the Duke because she believes he is stealing her thunder and that he is attempting to diminish her position by calling out to her in public. She also feels that he is not genuinely interested in her, and that he is trying to impress others with his affection for her, rather than truly loving her.\n",
            "   Context (ilk 100 karakter): [1]  face and with a wild sob darted away from him. She was leaning\n",
            "now against the window, her head...\n",
            "\n",
            "3. Soru: Who is the first person Zuleika falls in love with?\n",
            "   Cevap: The context doesn‚Äôt explicitly state who Zuleika falls in love with. It focuses on her feelings towards the youth and her own feelings of being adored by them.\n",
            "   Context (ilk 100 karakter): [1]  sanguine aversion. She could love none but a youth. Nor--though\n",
            "she herself, womanly, would utt...\n"
          ]
        }
      ],
      "source": [
        "# RAG ile cevapla\n",
        "print(\"RAG pipeline ile sorular cevaplanƒ±yor...\")\n",
        "rag_results = rag_pipeline.batch_answer_questions(\n",
        "    questions,\n",
        "    top_k_children=5,\n",
        "    max_new_tokens=200\n",
        ")\n",
        "\n",
        "print(f\"\\n{len(rag_results)} soru cevaplandƒ±!\")\n",
        "\n",
        "# ƒ∞lk 3 cevabƒ± g√∂ster\n",
        "print(\"\\n√ñrnek RAG Cevaplar:\")\n",
        "for i, result in enumerate(rag_results[:3], 1):\n",
        "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
        "    print(f\"   Cevap: {result['answer']}\")\n",
        "    print(f\"   Context (ilk 100 karakter): {result['context'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQQVccp3h9ag"
      },
      "source": [
        "---\n",
        "## 7. Performans Deƒüerlendirme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prNRSNKPh9ag"
      },
      "source": [
        "### 7.1 BLEU ve ROUGE Metrikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YVv9bgzLh9ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2b9612-2e0f-4326-c9fb-ee3d809a6377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG metrikleri hesaplaniyor...\n",
            "Baseline metrikleri hesaplaniyor...\n",
            "\n",
            "============================================================\n",
            "MODEL KARSILASTIRMASI\n",
            "============================================================\n",
            "\n",
            "RAG Sistemi:\n",
            "  BLEU:    2.22\n",
            "  ROUGE-1: 21.31\n",
            "  ROUGE-2: 6.67\n",
            "  ROUGE-L: 20.09\n",
            "\n",
            "Baseline (RAG'siz):\n",
            "  BLEU:    1.01\n",
            "  ROUGE-1: 14.27\n",
            "  ROUGE-2: 4.41\n",
            "  ROUGE-L: 13.44\n",
            "\n",
            "Iyilestirme (RAG - Baseline):\n",
            "  BLEU:    +1.21\n",
            "  ROUGE-1: +7.04\n",
            "  ROUGE-2: +2.26\n",
            "  ROUGE-L: +6.64\n",
            "============================================================\n",
            "\n",
            "Sonuclar kaydedildi: results/rag_vs_baseline.json\n"
          ]
        }
      ],
      "source": [
        "# Metrics evaluator olu≈ütur\n",
        "evaluator = MetricsEvaluator()\n",
        "\n",
        "# RAG vs Baseline kar≈üƒ±la≈ütƒ±r\n",
        "comparison = evaluator.compare_models(\n",
        "    rag_results=rag_results,\n",
        "    baseline_results=baseline_results,\n",
        "    ground_truth=test_df\n",
        ")\n",
        "\n",
        "# Sonu√ßlarƒ± yazdƒ±r\n",
        "evaluator.print_comparison(comparison)\n",
        "\n",
        "# Sonu√ßlarƒ± kaydet\n",
        "evaluator.save_results(comparison, \"results/rag_vs_baseline.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMKXXZmh9ag"
      },
      "source": [
        "### 7.2 Sonu√ßlarƒ± G√∂rselle≈ütirme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aJnN43Zxh9ah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "edde61cb-f884-4f08-a5a4-a08f86bc79b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grafik kaydedildi: results/rag_vs_baseline.png\n"
          ]
        }
      ],
      "source": [
        "# Kar≈üƒ±la≈ütƒ±rma grafiƒüi\n",
        "metrics = ['bleu', 'rouge1', 'rouge2', 'rougeL']\n",
        "rag_scores = [comparison['rag'][m] for m in metrics]\n",
        "baseline_scores = [comparison['baseline'][m] for m in metrics]\n",
        "\n",
        "x = range(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar([i - width/2 for i in x], rag_scores, width, label='RAG', color='green')\n",
        "ax.bar([i + width/2 for i in x], baseline_scores, width, label='Baseline', color='blue')\n",
        "\n",
        "ax.set_xlabel('Metrikler', fontsize=12)\n",
        "ax.set_ylabel('Skor', fontsize=12)\n",
        "ax.set_title('RAG vs Baseline Performans Kar≈üƒ±la≈ütƒ±rmasƒ±', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([m.upper() for m in metrics])\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/rag_vs_baseline.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"grafik kaydedildi: results/rag_vs_baseline.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQRyJFj3h9am"
      },
      "source": [
        "---\n",
        "## 8. Hiperparametre Optimizasyonu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jWPjjkh9am"
      },
      "source": [
        "### 8.2 Grid Search  (K√º√ß√ºk Subset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import itertools\n",
        "from typing import Dict, List\n",
        "\n",
        "runner = ExperimentRunner(\n",
        "    book_path=data_paths['book'],\n",
        "    test_questions_path=data_paths['test'],\n",
        "    results_dir=\"results/experiments\"\n",
        ")\n",
        "\n",
        "def run_grid_search_parallel(self, chunk_sizes: List[int], overlaps: List[int],\n",
        "                             temperatures: List[float], max_workers: int = 2) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Paralel grid search (batch'li, guvenli)\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    experiments = list(itertools.product(chunk_sizes, overlaps, temperatures))\n",
        "    total_experiments = len(experiments)\n",
        "\n",
        "    print(f\"\\nToplam {total_experiments} deney {max_workers} worker ile calistirilacak\")\n",
        "    print(\"‚ö†Ô∏è GPU memory'yi izle! Sorun olursa max_workers=1 yap\\n\")\n",
        "\n",
        "    completed = 0\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_config = {}\n",
        "        for chunk_size, overlap, temperature in experiments:\n",
        "            future = executor.submit(\n",
        "                self.run_single_experiment,\n",
        "                chunk_size, overlap, temperature\n",
        "            )\n",
        "            future_to_config[future] = (chunk_size, overlap, temperature)\n",
        "\n",
        "        for future in as_completed(future_to_config):\n",
        "            config = future_to_config[future]\n",
        "            completed += 1\n",
        "\n",
        "            try:\n",
        "                result = future.result()\n",
        "                all_results.append(result)\n",
        "                print(f\"\\n‚úÖ ƒ∞lerleme: {completed}/{total_experiments}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ùå Hata ({config}): {e}\")\n",
        "                continue\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Fonksiyonu runner'a ekle\n",
        "runner.run_grid_search_parallel = run_grid_search_parallel.__get__(runner, ExperimentRunner)\n",
        "\n",
        "\n",
        "\n",
        "CHUNK_SIZES_SUBSET = [50, 100, 256, 512]\n",
        "OVERLAPS_SUBSET = [0, 25, 50, 100]\n",
        "TEMPERATURES_SUBSET = [0.01, 0.1, 0.4, 0.6, 0.8]\n",
        "\n",
        "# Paralel √ßalƒ±≈ütƒ±rma\n",
        "all_results = runner.run_grid_search_parallel(\n",
        "    chunk_sizes=CHUNK_SIZES_SUBSET,\n",
        "    overlaps=OVERLAPS_SUBSET,\n",
        "    temperatures=TEMPERATURES_SUBSET,\n",
        "    max_workers=2  # GPU memory'ye g√∂re 1 veya 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OpH0HvJIt9wf",
        "outputId": "94159d7d-ddd1-49a3-aa2e-69eec42379bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Toplam 80 deney 2 worker ile calistirilacak\n",
            "‚ö†Ô∏è GPU memory'yi izle! Sorun olursa max_workers=1 yap\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Deney: child_size=50, overlap=0, temperature=0.01\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Deney: child_size=50, overlap=0, temperature=0.1\n",
            "======================================================================\n",
            "\n",
            "1. Chunking yapiliyor...\n",
            "\n",
            "1. Chunking yapiliyor...\n",
            "Toplam 1131 parent chunk olusturuldu\n",
            "Toplam 2261 child chunk olusturuldu\n",
            "\n",
            "2. Vector store olusturuluyor ve indexleniyor...\n",
            "Embedding modeli yukleniyor: all-MiniLM-L6-v2\n",
            "Toplam 1131 parent chunk olusturuldu\n",
            "Toplam 2261 child chunk olusturuldu\n",
            "\n",
            "2. Vector store olusturuluyor ve indexleniyor...\n",
            "Embedding modeli yukleniyor: all-MiniLM-L6-v2\n",
            "\n",
            "======================================================================\n",
            "‚ùå Hata ((50, 0, 0.1)): <MilvusException: (code=2, message=Fail connecting to server on unix:/tmp/tmp_7egl05j_milvus_c50_o0_t0.1.db.sock, illegal connection params or server unavailable)>\n",
            "\n",
            "Deney: child_size=50, overlap=0, temperature=0.4\n",
            "======================================================================\n",
            "\n",
            "1. Chunking yapiliyor...\n",
            "Toplam 1131 parent chunk olusturuldu\n",
            "Toplam 2261 child chunk olusturuldu\n",
            "\n",
            "2. Vector store olusturuluyor ve indexleniyor...\n",
            "Embedding modeli yukleniyor: all-MiniLM-L6-v2\n",
            "Collection'lar olusturuldu: parent_chunks, child_chunks\n",
            "1131 parent chunk eklendi\n",
            "2261 child chunk eklendi\n",
            "\n",
            "3. Sorular cevaplanƒ±yor...\n",
            "Cihaz: cuda\n",
            "Model yukleniyor: google/gemma-3-1b-it\n",
            "Model yuklendi!\n",
            "  Soru 1/40 - 1.42s\n",
            "  Soru 2/40 - 2.96s\n",
            "  Soru 3/40 - 0.49s\n",
            "  Soru 4/40 - 0.73s\n",
            "  Soru 5/40 - 2.85s\n",
            "  Soru 6/40 - 2.08s\n",
            "  Soru 7/40 - 1.54s\n",
            "  Soru 8/40 - 1.87s\n",
            "  Soru 9/40 - 1.02s\n",
            "  Soru 10/40 - 0.41s\n",
            "  Soru 11/40 - 1.17s\n",
            "  Soru 12/40 - 1.81s\n",
            "  Soru 13/40 - 0.72s\n",
            "  Soru 14/40 - 1.09s\n",
            "  Soru 15/40 - 0.67s\n",
            "  Soru 16/40 - 2.20s\n",
            "  Soru 17/40 - 0.64s\n",
            "  Soru 18/40 - 0.21s\n",
            "  Soru 19/40 - 0.49s\n",
            "  Soru 20/40 - 0.77s\n",
            "  Soru 21/40 - 1.63s\n",
            "  Soru 22/40 - 2.25s\n",
            "  Soru 23/40 - 1.28s\n",
            "  Soru 24/40 - 1.17s\n",
            "  Soru 25/40 - 0.84s\n",
            "  Soru 26/40 - 1.55s\n",
            "  Soru 27/40 - 1.81s\n",
            "  Soru 28/40 - 0.35s\n",
            "  Soru 29/40 - 0.17s\n",
            "  Soru 30/40 - 0.45s\n",
            "  Soru 31/40 - 0.60s\n",
            "  Soru 32/40 - 0.79s\n",
            "  Soru 33/40 - 2.33s\n",
            "  Soru 34/40 - 1.91s\n",
            "  Soru 35/40 - 0.77s\n",
            "  Soru 36/40 - 4.74s\n",
            "  Soru 37/40 - 0.74s\n",
            "  Soru 38/40 - 0.26s\n",
            "  Soru 39/40 - 2.48s\n",
            "  Soru 40/40 - 1.41s\n",
            "\n",
            "4. Metrikler hesaplaniyor...\n",
            "\n",
            "5. Retrieval kalitesi olculuyor...\n",
            "\n",
            "Deney tamamlandi! Toplam sure: 65.41s\n",
            "\n",
            "======================================================================\n",
            "Deney: child_size=50, overlap=0, temperature=0.6\n",
            "======================================================================\n",
            "\n",
            "‚úÖ ƒ∞lerleme: 2/80\n",
            "\n",
            "1. Chunking yapiliyor...\n",
            "Toplam 1131 parent chunk olusturuldu\n",
            "Toplam 2261 child chunk olusturuldu\n",
            "\n",
            "2. Vector store olusturuluyor ve indexleniyor...\n",
            "Embedding modeli yukleniyor: all-MiniLM-L6-v2\n",
            "\n",
            "======================================================================\n",
            "‚ùå Hata ((50, 0, 0.6)): <MilvusException: (code=2, message=Fail connecting to server on unix:/tmp/tmpptitk9ap_milvus_c50_o0_t0.6.db.sock, illegal connection params or server unavailable)>\n",
            "\n",
            "Deney: child_size=50, overlap=0, temperature=0.8\n",
            "======================================================================\n",
            "\n",
            "1. Chunking yapiliyor...\n",
            "Toplam 1131 parent chunk olusturuldu\n",
            "Toplam 2261 child chunk olusturuldu\n",
            "\n",
            "2. Vector store olusturuluyor ve indexleniyor...\n",
            "Embedding modeli yukleniyor: all-MiniLM-L6-v2\n",
            "Collection'lar olusturuldu: parent_chunks, child_chunks\n",
            "1131 parent chunk eklendi\n",
            "2261 child chunk eklendi\n",
            "\n",
            "3. Sorular cevaplanƒ±yor...\n",
            "Cihaz: cuda\n",
            "Model yukleniyor: google/gemma-3-1b-it\n",
            "Model yuklendi!\n",
            "  Soru 1/40 - 1.55s\n",
            "  Soru 2/40 - 3.27s\n",
            "  Soru 3/40 - 0.49s\n",
            "  Soru 4/40 - 0.72s\n",
            "  Soru 5/40 - 1.64s\n",
            "  Soru 6/40 - 1.53s\n",
            "  Soru 7/40 - 1.55s\n",
            "  Soru 8/40 - 1.61s\n",
            "  Soru 9/40 - 0.99s\n",
            "  Soru 10/40 - 0.40s\n",
            "  Soru 11/40 - 1.69s\n",
            "  Soru 12/40 - 1.51s\n",
            "  Soru 13/40 - 0.72s\n",
            "  Soru 14/40 - 1.09s\n",
            "  Soru 15/40 - 0.69s\n",
            "  Soru 16/40 - 1.85s\n",
            "  Soru 17/40 - 0.65s\n",
            "  Soru 18/40 - 0.71s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1945979658.py\u001b[0m in \u001b[0;36mrun_grid_search_parallel\u001b[0;34m(self, chunk_sizes, overlaps, temperatures, max_workers)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_to_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_to_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1945979658.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Paralel √ßalƒ±≈ütƒ±rma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m all_results = runner.run_grid_search_parallel(\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHUNK_SIZES_SUBSET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0moverlaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOVERLAPS_SUBSET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1945979658.py\u001b[0m in \u001b[0;36mrun_grid_search_parallel\u001b[0;34m(self, chunk_sizes, overlaps, temperatures, max_workers)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mfuture_to_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HViwDZAh9am"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "CHUNK_SIZES_SUBSET = [50, 100, 256, 512]\n",
        "OVERLAPS_SUBSET = [0, 25, 50, 100]\n",
        "TEMPERATURES_SUBSET = [0.01, 0.1, 0.4, 0.6, 0.8]\n",
        "\n",
        "# Experiment runner olu≈ütur\n",
        "runner = ExperimentRunner(\n",
        "    book_path=data_paths['book'],\n",
        "    test_questions_path=data_paths['test'],\n",
        "    results_dir=\"results/experiments\"\n",
        ")\n",
        "\n",
        "# Grid search √ßalƒ±≈ütƒ±r\n",
        "print(\"Grid search ba≈ülatƒ±lƒ±yor (subset)...\")\n",
        "all_results = runner.run_grid_search(\n",
        "    chunk_sizes=CHUNK_SIZES_SUBSET,\n",
        "    overlaps=OVERLAPS_SUBSET,\n",
        "    temperatures=TEMPERATURES_SUBSET\n",
        ")\n",
        "\n",
        "# Sonu√ßlarƒ± kaydet\n",
        "runner.save_summary(all_results, summary_filename=\"experiment_summary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD78IZWHh9am"
      },
      "source": [
        "### 8.3 Experiment Sonu√ßlarƒ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6QhjVRxh9am"
      },
      "outputs": [],
      "source": [
        "exp_df1 = pd.read_csv('results/experiments/experiment_summary.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "baseline_metrics_data = {\n",
        "    'child_size': 'Baseline',\n",
        "    'parent_size': 'Baseline',\n",
        "    'overlap': 'Baseline',\n",
        "    'temperature': 0.5,\n",
        "    'bleu': comparison['baseline']['bleu'],\n",
        "    'rouge1': comparison['baseline']['rouge1'],\n",
        "    'rouge2': comparison['baseline']['rouge2'],\n",
        "    'rougeL': comparison['baseline']['rougeL']\n",
        "}\n",
        "\n",
        "baseline_series = pd.Series(index=exp_df1.columns, dtype=object)\n",
        "baseline_series.update(pd.Series(baseline_metrics_data))\n",
        "\n",
        "exp_df_final = pd.concat([exp_df1, pd.DataFrame(baseline_series).T], ignore_index=True)\n",
        "exp_df_final"
      ],
      "metadata": {
        "id": "X05Ba3bB91Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_ahKJG7h9am"
      },
      "source": [
        "### 8.4 En ƒ∞yi Parametreler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZePm1aG7h9am"
      },
      "outputs": [],
      "source": [
        "# BLEU'ya g√∂re sƒ±rala\n",
        "best_bleu = exp_df_final.nlargest(5, 'bleu')[['child_size', 'overlap', 'temperature', 'bleu', 'total_time']]\n",
        "print(\"En Y√ºksek BLEU Skorlarƒ±:\")\n",
        "print(best_bleu)\n",
        "\n",
        "# ROUGE-L'ye g√∂re sƒ±rala\n",
        "best_rougeL = exp_df_final.nlargest(5, 'rougeL')[['child_size', 'overlap', 'temperature', 'rougeL', 'total_time']]\n",
        "print(\"\\nEn Y√ºksek ROUGE-L Skorlarƒ±:\")\n",
        "print(best_rougeL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab7vxqzbh9am"
      },
      "source": [
        "### 8.5 Parametre Etkileri"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk size etkisi\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Chunk size vs BLEU\n",
        "exp_df_final.groupby('child_size')['bleu'].mean().plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Chunk Size vs BLEU')\n",
        "axes[0].set_xlabel('Child Chunk Size')\n",
        "axes[0].set_ylabel('Ortalama BLEU')\n",
        "\n",
        "# Overlap vs ROUGE-L\n",
        "exp_df_final.groupby('overlap')['rougeL'].mean().plot(kind='bar', ax=axes[1], color='lightcoral')\n",
        "axes[1].set_title('Overlap vs ROUGE-L')\n",
        "axes[1].set_xlabel('Overlap')\n",
        "axes[1].set_ylabel('Ortalama ROUGE-L')\n",
        "\n",
        "# Temperature vs ROUGE-1\n",
        "exp_df_final.groupby('temperature')['rouge1'].mean().plot(kind='bar', ax=axes[2], color='lightgreen')\n",
        "axes[2].set_title('Temperature vs ROUGE-1')\n",
        "axes[2].set_xlabel('Temperature')\n",
        "axes[2].set_ylabel('Ortalama ROUGE-1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/parameter_effects.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Grafik kaydedildi: results/parameter_effects.png\")"
      ],
      "metadata": {
        "id": "i6CXwanxBhSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWAk9C9Ph9am"
      },
      "source": [
        "---\n",
        "## 9. Kaynak Kullanƒ±mƒ± Analizi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTGjsnu2h9am"
      },
      "source": [
        "### 9.1 Memory ve Time Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQASV48Qh9am"
      },
      "outputs": [],
      "source": [
        "if len(exp_df1) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Memory kullanƒ±mƒ±\n",
        "    exp_df1.plot(x='child_size', y='memory_used_mb', kind='scatter', ax=axes[0], s=100, alpha=0.6)\n",
        "    axes[0].set_title('Chunk Size vs Memory Kullanƒ±mƒ±')\n",
        "    axes[0].set_xlabel('Child Chunk Size')\n",
        "    axes[0].set_ylabel('Memory (MB)')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Execution time\n",
        "    exp_df1.plot(x='child_size', y='total_time', kind='scatter', ax=axes[1], s=100, alpha=0.6, color='orange')\n",
        "    axes[1].set_title('Chunk Size vs Toplam S√ºre')\n",
        "    axes[1].set_xlabel('Child Chunk Size')\n",
        "    axes[1].set_ylabel('S√ºre (saniye)')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/resource_usage.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Grafik kaydedildi: results/resource_usage.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lnwTdlxh9am"
      },
      "source": [
        "### 9.2 Database Boyutu Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H6KhZbph9an"
      },
      "outputs": [],
      "source": [
        "if len(exp_df1) > 0:\n",
        "    # DB boyutlarƒ±nƒ± g√∂ster\n",
        "    db_stats = exp_df1.groupby('child_size')['db_size_mb'].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    db_stats.plot(kind='bar', color='purple', alpha=0.7)\n",
        "    plt.title('Ortalama Vector DB Boyutu')\n",
        "    plt.xlabel('Child Chunk Size')\n",
        "    plt.ylabel('DB Boyutu (MB)')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/db_size.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Grafik kaydedildi: results/db_size.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_z27fVh9an"
      },
      "source": [
        "---\n",
        "## 10. Sonu√ß ve G√∂zlemler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROEFg4r6h9an"
      },
      "source": [
        "### 10.1 Ana Bulgular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmAm4rulh9an"
      },
      "outputs": [],
      "source": [
        "print(\"PROJE √ñZETI VE BULGULAR\")\n",
        "\n",
        "\n",
        "print(\"\\n1. RAG vs Baseline Performansƒ±:\")\n",
        "print(f\"   - RAG BLEU: {comparison['rag']['bleu']:.2f}\")\n",
        "print(f\"   - Baseline BLEU: {comparison['baseline']['bleu']:.2f}\")\n",
        "print(f\"   - ƒ∞yile≈ütirme: {comparison['improvement']['bleu']:+.2f}\")\n",
        "\n",
        "if len(exp_df1) > 0:\n",
        "    print(\"\\n2. En ƒ∞yi Parametre Kombinasyonu:\")\n",
        "    best = exp_df1.loc[exp_df1['bleu'].idxmax()]\n",
        "    print(f\"   - Chunk Size: {best['child_size']}\")\n",
        "    print(f\"   - Overlap: {best['overlap']}\")\n",
        "    print(f\"   - Temperature: {best['temperature']}\")\n",
        "    print(f\"   - BLEU: {best['bleu']:.2f}\")\n",
        "\n",
        "print(\"\\n3. Kaynak Kullanƒ±mƒ±:\")\n",
        "print(f\"   - Ortalama indexing s√ºresi: {(parent_time + child_time):.2f}s\")\n",
        "print(f\"   - GPU kullanƒ±mƒ±: {'Evet' if torch.cuda.is_available() else 'Hayƒ±r'}\")\n",
        "\n",
        "print(\"\\n4. Zorluklar ve G√∂zlemler:\")\n",
        "print(\"   - Local machine kaynak kƒ±sƒ±tlarƒ± nedeniyle gemma3 √ßalƒ±≈ütƒ±ramadƒ±m, google colab √ºzerinde √ßalƒ±≈ütƒ±m. goo grid search uzun s√ºrd√º\")\n",
        "print(\"   - Hiyerar≈üik chunking, context kalitesini artƒ±rdƒ±\")\n",
        "print(\"   - Optimal chunk size ve overlap deƒüerleri veri setine baƒülƒ±\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKidN1wyh9an"
      },
      "source": [
        "### 10.2 T√ºm Sonu√ßlarƒ± Dƒ±≈üa Aktarmak i√ßin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZJ2ZaJ1h9an"
      },
      "outputs": [],
      "source": [
        "# T√ºm sonu√ßlarƒ± bir yerde topla\n",
        "final_report = {\n",
        "    'project_info': {\n",
        "        'book': 'Zuleika Dobson by Max Beerbohm',\n",
        "        'dataset': 'NarrativeQA',\n",
        "        'test_questions': len(test_df),\n",
        "        'vector_db': 'Milvus Lite',\n",
        "        'embedding_model': 'all-mpnet-base-v2',  #'all-MiniLM-L6-v2',\n",
        "        'llm': 'google/gemma-3-1b-it'\n",
        "    },\n",
        "    'chunk_stats': stats,\n",
        "    'rag_vs_baseline': comparison,\n",
        "    'best_config_for_blue': exp_df1.loc[exp_df1['bleu'].idxmax()].to_dict() if len(exp_df1) > 0 else None,\n",
        "    'best_config_for_rouge1': exp_df1.loc[exp_df1['rouge1'].idxmax()].to_dict() if len(exp_df1) > 0 else None,\n",
        "    'best_config_for_rouge2': exp_df1.loc[exp_df1['rouge2'].idxmax()].to_dict() if len(exp_df1) > 0 else None,\n",
        "    'best_config_for_rougeL': exp_df1.loc[exp_df1['rougeL'].idxmax()].to_dict() if len(exp_df1) > 0 else None\n",
        "}\n",
        "\n",
        "# JSON olarak kaydet\n",
        "with open('results/final_report.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Final rapor kaydedildi: results/final_report.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asmC3hQFh9an"
      },
      "source": [
        "---\n",
        "## Notlar ve ƒ∞yile≈ütirme √ñnerileri\n",
        "\n",
        "### G√∂zlemler:\n",
        "1. **Hiyerar≈üik Chunking:** Parent-child yapƒ±sƒ±, hem geni≈ü context hem de detaylƒ± bilgi saƒüladƒ±\n",
        "2. **Milvus Lite:** Disk-based yapƒ±sƒ± Colab i√ßin ideal, memory kullanƒ±mƒ± d√º≈ü√ºk\n",
        "3. **Hyperparameter Tuning:** Chunk size, overlap ve temperature'√ºn kombinasyonu performansƒ± etkiliyor\n",
        "\n",
        "### ƒ∞yile≈ütirme √ñnerileri:\n",
        "1. Reranking mekanizmasƒ± eklenebilir (Cross-encoder)\n",
        "2. Query expansion ile retrieval kalitesi artƒ±rƒ±labilir\n",
        "3. Daha b√ºy√ºk LLM'ler (7B, 13B) test edilebilir\n",
        "4. Multi-hop reasoning i√ßin iterative retrieval denenebilir\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pJFtiBuCAuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}