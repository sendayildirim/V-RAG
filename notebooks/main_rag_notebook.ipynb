{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOdTxV3ph9aa"
      },
      "source": [
        "# Hierarchical RAG System for Zuleika Dobson\n",
        "\n",
        "Bu notebook, Project Gutenberg'den \"Zuleika Dobson\" kitabını kullanarak hiyerarşik parçalama yöntemiyle bir RAG (Retrieval-Augmented Generation) sistemi oluşturur.\n",
        "\n",
        "**Proje Detayları:**\n",
        "- **Kitap:** Zuleika Dobson by Max Beerbohm\n",
        "- **Dataset:** NarrativeQA (İlgili kitap için 40 test sorusu)\n",
        "- **Vector DB:** Milvus Lite tercih ettim\n",
        "- **Embedding Model:** all-MiniLM-L6-v2\n",
        "- **LLM:** google/gemma-3-1b-it\n",
        "- **Metrikler:** BLEU, ROUGE-1, ROUGE-2, ROUGE-L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB7aTLVNh9ac"
      },
      "source": [
        "---\n",
        "## 1. Kurulum ve Hazırlık"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01oXF_MKh9ac"
      },
      "source": [
        "### 1.1 Git Repo & Kütüphaneler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n"
      ],
      "metadata": {
        "id": "i8z_sTQjnZ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbOETlmNh9ad"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if not os.path.exists('V-RAG'):\n",
        "    !git clone https://github.com/sendayildirim/V-RAG\n",
        "    %cd V-RAG\n",
        "else:\n",
        "    %cd V-RAG\n",
        "    !git pull\n",
        "\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "print(\"proje yüklendi\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dh2Uddoh9ae"
      },
      "source": [
        "### 1.2 Gerekli Modülleri İçe Aktar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KWI5gjNh9ae"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from data_loader import DataLoader\n",
        "from chunker import HierarchicalChunker\n",
        "from vector_store import VectorStore\n",
        "from rag_pipeline import RAGPipeline\n",
        "from baseline_model import BaselineModel\n",
        "from metrics import MetricsEvaluator\n",
        "from experiment_runner import ExperimentRunner\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import torch\n",
        "\n",
        "##Cobal Runtime alanından Hardware accelerator'ı NVIDIA A100-SXM4-40GB olarak değiştirdim. (pro üyeliğim var olduğundan)\n",
        "\n",
        "print(\"modüller yüklendi!\")\n",
        "print(f\"GPU kullanılabilme durumu: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YOkP4EIh9ae"
      },
      "source": [
        "---\n",
        "## 2. Veri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wULKTPAUh9af"
      },
      "source": [
        "### 2.1 Kitap ve Sorular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEwrKS6Fh9af"
      },
      "outputs": [],
      "source": [
        "# Data loader oluştur ve verileri indir\n",
        "loader = DataLoader(data_dir=\"data\")\n",
        "data_paths = loader.load_all_data()\n",
        "\n",
        "print(\"\\nİndirilen dosyalar:\")\n",
        "print(f\"  book: {data_paths['book']}\")\n",
        "print(f\"  test: {data_paths['test']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbx6Abuxh9af"
      },
      "source": [
        "### 2.2 Test Verisi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lryey0PXh9af"
      },
      "outputs": [],
      "source": [
        "# Test sorularını yükle\n",
        "test_df = pd.read_csv(data_paths['test'])\n",
        "\n",
        "print(f\"Toplam test sorusu: {len(test_df)}\")\n",
        "print(\"\\nİlk 3 soru:\")\n",
        "print(test_df[['question', 'answer1', 'answer2']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFDeB0U3h9af"
      },
      "source": [
        "---\n",
        "## 3. Hiyerarşik Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlSpOei6h9af"
      },
      "source": [
        "### 3.1 Chunker oluşturma ve metni parçalama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1XTXWQbh9af"
      },
      "outputs": [],
      "source": [
        "# Kitap metnini yükle\n",
        "with open(data_paths['book'], 'r', encoding='utf-8') as f:\n",
        "    book_text = f.read()\n",
        "\n",
        "print(f\"Kitap uzunluğu: {len(book_text)} karakter\")\n",
        "\n",
        "# Chunker oluştur (Parent: 512, Child: 256, Overlap: 50)\n",
        "chunker = HierarchicalChunker(\n",
        "    parent_size=512,\n",
        "    child_size=256,\n",
        "    overlap=50\n",
        ")\n",
        "\n",
        "# Metni parçala\n",
        "parent_chunks, child_chunks = chunker.chunk_text(book_text)\n",
        "\n",
        "# İstatistikler\n",
        "stats = chunker.get_chunk_stats(parent_chunks, child_chunks)\n",
        "print(\"\\nChunk İstatistikleri:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"  {key}: {value:.1f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqjZQA81h9ag"
      },
      "source": [
        "### 3.2 Chunk Örnekleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPaqZarih9ag"
      },
      "outputs": [],
      "source": [
        "# Bir parent chunk ve onun child'larını göster\n",
        "sample_parent = parent_chunks[0]\n",
        "sample_children = [c for c in child_chunks if c['parent_id'] == sample_parent['id']]\n",
        "\n",
        "print(\"Örnek Parent Chunk:\")\n",
        "print(f\"ID: {sample_parent['id']}\")\n",
        "print(f\"Token sayısı: {sample_parent['token_count']}\")\n",
        "print(f\"Metin (ilk 200 karakter): {sample_parent['text'][:200]}...\")\n",
        "\n",
        "print(\"\\nBu parent'ın child chunk'ları:\")\n",
        "for child in sample_children:\n",
        "    print(f\"  - {child['id']}: {child['token_count']} token\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYyjC5Zmh9ag"
      },
      "source": [
        "---\n",
        "## 4. Vector Store ve Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yl9Wzhlh9ag"
      },
      "source": [
        "### 4.1 Milvus Lite Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmUzZwHkh9ag"
      },
      "outputs": [],
      "source": [
        "# Vector store oluştur\n",
        "vector_store = VectorStore(\n",
        "    db_path=\"./milvus_rag.db\",\n",
        "    model_name=\"all-mpnet-base-v2\"  #\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# Collection'ları oluştur\n",
        "vector_store.create_collections()\n",
        "\n",
        "print(f\"Embedding boyutu: {vector_store.embedding_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHiYxOShh9ag"
      },
      "source": [
        "### 4.2 Chunk'ları indeksleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9yzyv2Rh9ag"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Parent chunk'ları ekle\n",
        "start = time.time()\n",
        "vector_store.insert_parent_chunks(parent_chunks)\n",
        "parent_time = time.time() - start\n",
        "\n",
        "# Child chunk'ları ekle\n",
        "start = time.time()\n",
        "vector_store.insert_child_chunks(child_chunks)\n",
        "child_time = time.time() - start\n",
        "\n",
        "print(f\"\\nParent indexing süresi: {parent_time:.2f}s\")\n",
        "print(f\"Child indexing süresi: {child_time:.2f}s\")\n",
        "print(f\"Toplam indexing süresi: {parent_time + child_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqWxDBhxh9ag"
      },
      "source": [
        "### 4.3 Retrieval Testi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj3vGy0jh9ag"
      },
      "outputs": [],
      "source": [
        "# Test sorusu ile retrieval dene\n",
        "test_query = \"Who are Zuleika's most prominent suitors?\"\n",
        "\n",
        "parent_results, child_results = vector_store.hybrid_search(\n",
        "    query=test_query,\n",
        "    top_parents=3,\n",
        "    top_children=5\n",
        ")\n",
        "\n",
        "print(f\"Test sorusu: {test_query}\")\n",
        "print(f\"\\nBulunan {len(child_results)} child chunk:\")\n",
        "for i, result in enumerate(child_results[:3], 1):\n",
        "    print(f\"\\n{i}. Score: {result['score']:.4f}\")\n",
        "    print(f\"   Metin: {result['text'][:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlZeDg58h9ag"
      },
      "source": [
        "---\n",
        "## 5. Baseline Model (RAG'sız)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF_XrtIjh9ag"
      },
      "source": [
        "### 5.1 Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ],
      "metadata": {
        "id": "qEhLYqc2x20m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSIV25vzh9ag"
      },
      "outputs": [],
      "source": [
        "# Baseline model oluştur\n",
        "baseline = BaselineModel(model_name=\"google/gemma-3-1b-it\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p980w-Kh9ag"
      },
      "source": [
        "### 5.2 Baseline ile Test Soruları"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbr2dLS9h9ag"
      },
      "outputs": [],
      "source": [
        "# Test sorularını al\n",
        "questions = test_df['question'].tolist()\n",
        "\n",
        "# Baseline ile cevapla\n",
        "print(\"Baseline model ile sorular cevaplanıyor...\")\n",
        "baseline_results = baseline.batch_answer_questions(questions, max_new_tokens=100)\n",
        "\n",
        "print(f\"\\n{len(baseline_results)} soru cevaplandı!\")\n",
        "\n",
        "# İlk 3 cevabı göster\n",
        "print(\"\\nÖrnek Baseline Cevaplar:\")\n",
        "for i, result in enumerate(baseline_results[:3], 1):\n",
        "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
        "    print(f\"   Cevap: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "id": "rwV4usqNWElv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_df = pd.DataFrame(baseline_results)\n",
        "\n",
        "os.makedirs(\"/content/V-RAG/results\", exist_ok=True)\n",
        "baseline_df.to_csv(\"/content/V-RAG/results/baseline_QA.csv\", index=False)"
      ],
      "metadata": {
        "id": "0GxKSkvTWtcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6CaIeUUh9ag"
      },
      "source": [
        "---\n",
        "## 6. RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RMQEgoAh9ag"
      },
      "source": [
        "### 6.1 RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqNratewh9ag"
      },
      "outputs": [],
      "source": [
        "# RAG pipeline oluştur\n",
        "rag_pipeline = RAGPipeline(\n",
        "    vector_store=vector_store,\n",
        "    model_name=\"google/gemma-3-1b-it\",\n",
        "    temperature=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3stgbuh9ag"
      },
      "source": [
        "### 6.2 RAG ile Test Soruları"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJkunDith9ag"
      },
      "outputs": [],
      "source": [
        "# RAG ile cevapla\n",
        "print(\"RAG pipeline ile sorular cevaplanıyor...\")\n",
        "rag_results = rag_pipeline.batch_answer_questions(\n",
        "    questions,\n",
        "    top_k_children=5,\n",
        "    max_new_tokens=200\n",
        ")\n",
        "\n",
        "print(f\"\\n{len(rag_results)} soru cevaplandı!\")\n",
        "\n",
        "# İlk 3 cevabı göster\n",
        "print(\"\\nÖrnek RAG Cevaplar:\")\n",
        "for i, result in enumerate(rag_results[:3], 1):\n",
        "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
        "    print(f\"   Cevap: {result['answer']}\")\n",
        "    print(f\"   Context (ilk 100 karakter): {result['context'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQQVccp3h9ag"
      },
      "source": [
        "---\n",
        "## 7. Performans Değerlendirme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prNRSNKPh9ag"
      },
      "source": [
        "### 7.1 BLEU ve ROUGE Metrikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVv9bgzLh9ag"
      },
      "outputs": [],
      "source": [
        "# Metrics evaluator oluştur\n",
        "evaluator = MetricsEvaluator()\n",
        "\n",
        "# RAG vs Baseline karşılaştır\n",
        "comparison = evaluator.compare_models(\n",
        "    rag_results=rag_results,\n",
        "    baseline_results=baseline_results,\n",
        "    ground_truth=test_df\n",
        ")\n",
        "\n",
        "# Sonuçları yazdır\n",
        "evaluator.print_comparison(comparison)\n",
        "\n",
        "# Sonuçları kaydet\n",
        "evaluator.save_results(comparison, \"results/rag_vs_baseline.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMKXXZmh9ag"
      },
      "source": [
        "### 7.2 Sonuçları Görselleştirme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJnN43Zxh9ah"
      },
      "outputs": [],
      "source": [
        "# Karşılaştırma grafiği\n",
        "metrics = ['bleu', 'rouge1', 'rouge2', 'rougeL']\n",
        "rag_scores = [comparison['rag'][m] for m in metrics]\n",
        "baseline_scores = [comparison['baseline'][m] for m in metrics]\n",
        "\n",
        "x = range(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar([i - width/2 for i in x], rag_scores, width, label='RAG', color='green')\n",
        "ax.bar([i + width/2 for i in x], baseline_scores, width, label='Baseline', color='blue')\n",
        "\n",
        "ax.set_xlabel('Metrikler', fontsize=12)\n",
        "ax.set_ylabel('Skor', fontsize=12)\n",
        "ax.set_title('RAG vs Baseline Performans Karşılaştırması', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([m.upper() for m in metrics])\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/rag_vs_baseline.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"grafik kaydedildi: results/rag_vs_baseline.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQRyJFj3h9am"
      },
      "source": [
        "---\n",
        "## 8. Hiperparametre Optimizasyonu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jWPjjkh9am"
      },
      "source": [
        "### 8.2 Grid Search  (Küçük Subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HViwDZAh9am"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "CHUNK_SIZES_SUBSET = [256, 512,1024]\n",
        "OVERLAPS_SUBSET = [0, 25, 50, 100]\n",
        "TEMPERATURES_SUBSET = [0.01, 0.1, 0.4, 0.6, 0.8]\n",
        "\n",
        "# Experiment runner oluştur\n",
        "runner = ExperimentRunner(\n",
        "    book_path=data_paths['book'],\n",
        "    test_questions_path=data_paths['test'],\n",
        "    results_dir=\"results/experiments\"\n",
        ")\n",
        "\n",
        "# Grid search çalıştır\n",
        "print(\"Grid search başlatılıyor (subset)...\")\n",
        "all_results = runner.run_grid_search(\n",
        "    chunk_sizes=CHUNK_SIZES_SUBSET,\n",
        "    overlaps=OVERLAPS_SUBSET,\n",
        "    temperatures=TEMPERATURES_SUBSET\n",
        ")\n",
        "\n",
        "# Sonuçları kaydet\n",
        "runner.save_summary(all_results, summary_filename=\"experiment_summary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD78IZWHh9am"
      },
      "source": [
        "### 8.3 Experiment Sonuçları"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6QhjVRxh9am"
      },
      "outputs": [],
      "source": [
        "exp_df1 = pd.read_csv('results/experiments/experiment_summary.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "baseline_metrics_data = {\n",
        "    'child_size': 'Baseline',\n",
        "    'parent_size': 'Baseline',\n",
        "    'overlap': 'Baseline',\n",
        "    'temperature': 0.5,\n",
        "    'bleu': comparison['baseline']['bleu'],\n",
        "    'rouge1': comparison['baseline']['rouge1'],\n",
        "    'rouge2': comparison['baseline']['rouge2'],\n",
        "    'rougeL': comparison['baseline']['rougeL']\n",
        "}\n",
        "\n",
        "baseline_series = pd.Series(index=exp_df1.columns, dtype=object)\n",
        "baseline_series.update(pd.Series(baseline_metrics_data))\n",
        "\n",
        "exp_df_final = pd.concat([exp_df1, pd.DataFrame(baseline_series).T], ignore_index=True)\n",
        "exp_df_final"
      ],
      "metadata": {
        "id": "X05Ba3bB91Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_ahKJG7h9am"
      },
      "source": [
        "### 8.4 En İyi Parametreler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZePm1aG7h9am"
      },
      "outputs": [],
      "source": [
        "# BLEU'ya göre sırala\n",
        "best_bleu = exp_df_final.nlargest(5, 'bleu')[['child_size', 'overlap', 'temperature', 'bleu', 'total_time']]\n",
        "print(\"En Yüksek BLEU Skorları:\")\n",
        "print(best_bleu)\n",
        "\n",
        "# ROUGE-L'ye göre sırala\n",
        "best_rougeL = exp_df_final.nlargest(5, 'rougeL')[['child_size', 'overlap', 'temperature', 'rougeL', 'total_time']]\n",
        "print(\"\\nEn Yüksek ROUGE-L Skorları:\")\n",
        "print(best_rougeL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab7vxqzbh9am"
      },
      "source": [
        "### 8.5 Parametre Etkileri"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk size etkisi\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Chunk size vs BLEU\n",
        "exp_df_final.groupby('child_size')['bleu'].mean().plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Chunk Size vs BLEU')\n",
        "axes[0].set_xlabel('Child Chunk Size')\n",
        "axes[0].set_ylabel('Ortalama BLEU')\n",
        "\n",
        "# Overlap vs ROUGE-L\n",
        "exp_df_final.groupby('overlap')['rougeL'].mean().plot(kind='bar', ax=axes[1], color='lightcoral')\n",
        "axes[1].set_title('Overlap vs ROUGE-L')\n",
        "axes[1].set_xlabel('Overlap')\n",
        "axes[1].set_ylabel('Ortalama ROUGE-L')\n",
        "\n",
        "# Temperature vs ROUGE-1\n",
        "exp_df_final.groupby('temperature')['rouge1'].mean().plot(kind='bar', ax=axes[2], color='lightgreen')\n",
        "axes[2].set_title('Temperature vs ROUGE-1')\n",
        "axes[2].set_xlabel('Temperature')\n",
        "axes[2].set_ylabel('Ortalama ROUGE-1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/parameter_effects.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Grafik kaydedildi: results/parameter_effects.png\")"
      ],
      "metadata": {
        "id": "i6CXwanxBhSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWAk9C9Ph9am"
      },
      "source": [
        "---\n",
        "## 9. Kaynak Kullanımı Analizi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTGjsnu2h9am"
      },
      "source": [
        "### 9.1 Memory ve Time Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQASV48Qh9am"
      },
      "outputs": [],
      "source": [
        "if len(exp_df1) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Memory kullanımı\n",
        "    exp_df1.plot(x='child_size', y='memory_used_mb', kind='scatter', ax=axes[0], s=100, alpha=0.6)\n",
        "    axes[0].set_title('Chunk Size vs Memory Kullanımı')\n",
        "    axes[0].set_xlabel('Child Chunk Size')\n",
        "    axes[0].set_ylabel('Memory (MB)')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Execution time\n",
        "    exp_df1.plot(x='child_size', y='total_time', kind='scatter', ax=axes[1], s=100, alpha=0.6, color='orange')\n",
        "    axes[1].set_title('Chunk Size vs Toplam Süre')\n",
        "    axes[1].set_xlabel('Child Chunk Size')\n",
        "    axes[1].set_ylabel('Süre (saniye)')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/resource_usage.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Grafik kaydedildi: results/resource_usage.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lnwTdlxh9am"
      },
      "source": [
        "### 9.2 Database Boyutu Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H6KhZbph9an"
      },
      "outputs": [],
      "source": [
        "if len(exp_df1) > 0:\n",
        "    # DB boyutlarını göster\n",
        "    db_stats = exp_df1.groupby('child_size')['db_size_mb'].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    db_stats.plot(kind='bar', color='purple', alpha=0.7)\n",
        "    plt.title('Ortalama Vector DB Boyutu')\n",
        "    plt.xlabel('Child Chunk Size')\n",
        "    plt.ylabel('DB Boyutu (MB)')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/db_size.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Grafik kaydedildi: results/db_size.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_z27fVh9an"
      },
      "source": [
        "---\n",
        "## 10. Sonuç ve Gözlemler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROEFg4r6h9an"
      },
      "source": [
        "### 10.1 Ana Bulgular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmAm4rulh9an"
      },
      "outputs": [],
      "source": [
        "print(\"PROJE ÖZETI VE BULGULAR\")\n",
        "\n",
        "\n",
        "print(\"\\n1. RAG vs Baseline Performansı:\")\n",
        "print(f\"   - RAG BLEU: {comparison['rag']['bleu']:.2f}\")\n",
        "print(f\"   - Baseline BLEU: {comparison['baseline']['bleu']:.2f}\")\n",
        "print(f\"   - İyileştirme: {comparison['improvement']['bleu']:+.2f}\")\n",
        "\n",
        "if len(exp_df1) > 0:\n",
        "    print(\"\\n2. En İyi Parametre Kombinasyonu:\")\n",
        "    best = exp_df1.loc[exp_df1['bleu'].idxmax()]\n",
        "    print(f\"   - Chunk Size: {best['child_size']}\")\n",
        "    print(f\"   - Overlap: {best['overlap']}\")\n",
        "    print(f\"   - Temperature: {best['temperature']}\")\n",
        "    print(f\"   - BLEU: {best['bleu']:.2f}\")\n",
        "\n",
        "print(\"\\n3. Kaynak Kullanımı:\")\n",
        "print(f\"   - Ortalama indexing süresi: {(parent_time + child_time):.2f}s\")\n",
        "print(f\"   - GPU kullanımı: {'Evet' if torch.cuda.is_available() else 'Hayır'}\")\n",
        "\n",
        "print(\"\\n4. Zorluklar ve Gözlemler:\")\n",
        "print(\"   - Local machine kaynak kısıtları nedeniyle gemma3 çalıştıramadım, google colab üzerinde çalıştım. goo grid search uzun sürdü\")\n",
        "print(\"   - Hiyerarşik chunking, context kalitesini artırdı\")\n",
        "print(\"   - Optimal chunk size ve overlap değerleri veri setine bağlı\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKidN1wyh9an"
      },
      "source": [
        "### 10.2 Tüm Sonuçları Dışa Aktarmak için"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZJ2ZaJ1h9an"
      },
      "outputs": [],
      "source": [
        "# Tüm sonuçları bir yerde topla\n",
        "final_report = {\n",
        "    'project_info': {\n",
        "        'book': 'Zuleika Dobson by Max Beerbohm',\n",
        "        'dataset': 'NarrativeQA',\n",
        "        'test_questions': len(test_df),\n",
        "        'vector_db': 'Milvus Lite',\n",
        "        'embedding_model': 'all-mpnet-base-v2',  #'all-MiniLM-L6-v2',\n",
        "        'llm': 'google/gemma-3-1b-it'\n",
        "    },\n",
        "    'chunk_stats': stats,\n",
        "    'rag_vs_baseline': comparison,\n",
        "    'best_config_for_blue': exp_df1.loc[exp_df1['bleu'].idxmax()].to_dict() if len(exp_df1) > 0 else None,\n",
        "    'best_config_for_rouge1': exp_df1.loc[exp_df1['rouge1'].idxmax()].to_dict() if len(exp_df1) > 0 else None,\n",
        "    'best_config_for_rouge2': exp_df1.loc[exp_df1['rouge2'].idxmax()].to_dict() if len(exp_df1) > 0 else None,\n",
        "    'best_config_for_rougeL': exp_df1.loc[exp_df1['rougeL'].idxmax()].to_dict() if len(exp_df1) > 0 else None\n",
        "}\n",
        "\n",
        "# JSON olarak kaydet\n",
        "with open('results/final_report.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Final rapor kaydedildi: results/final_report.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asmC3hQFh9an"
      },
      "source": [
        "---\n",
        "## Notlar ve İyileştirme Önerileri\n",
        "\n",
        "### Gözlemler:\n",
        "1. **Hiyerarşik Chunking:** Parent-child yapısı, hem geniş context hem de detaylı bilgi sağladı\n",
        "2. **Milvus Lite:** Disk-based yapısı Colab için ideal, memory kullanımı düşük\n",
        "3. **Hyperparameter Tuning:** Chunk size, overlap ve temperature'ün kombinasyonu performansı etkiliyor\n",
        "\n",
        "### İyileştirme Önerileri:\n",
        "1. Reranking mekanizması eklenebilir (Cross-encoder)\n",
        "2. Query expansion ile retrieval kalitesi artırılabilir\n",
        "3. Daha büyük LLM'ler (7B, 13B) test edilebilir\n",
        "4. Multi-hop reasoning için iterative retrieval denenebilir\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pJFtiBuCAuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}