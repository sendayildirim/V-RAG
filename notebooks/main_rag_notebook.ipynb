{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOdTxV3ph9aa"
      },
      "source": [
        "# Hierarchical RAG System for Zuleika Dobson\n",
        "\n",
        "Bu notebook, Project Gutenberg'den \"Zuleika Dobson\" kitabını kullanarak hiyerarşik parçalama yöntemiyle bir RAG (Retrieval-Augmented Generation) sistemi oluşturur.\n",
        "\n",
        "**Proje Detayları:**\n",
        "- **Kitap:** Zuleika Dobson by Max Beerbohm\n",
        "- **Dataset:** NarrativeQA (40 test sorusu)\n",
        "- **Vector DB:** Milvus Lite\n",
        "- **Embedding Model:** all-MiniLM-L6-v2\n",
        "- **LLM:** google/gemma-2-2b-it\n",
        "- **Metrikler:** BLEU, ROUGE-1, ROUGE-2, ROUGE-L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB7aTLVNh9ac"
      },
      "source": [
        "---\n",
        "## 1. Kurulum ve Hazırlık"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01oXF_MKh9ac"
      },
      "source": [
        "### 1.1 Kütüphaneleri Kur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbOETlmNh9ad",
        "outputId": "36a14da1-3ffe-4261-f883-c55ec9b28bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'V-RAG'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 36 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 224.68 KiB | 2.14 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/V-RAG/V-RAG/V-RAG/V-RAG/V-RAG\n",
            "proje yüklendi\n",
            "data  LICENSE  notebooks  README.md  requirements.txt  src\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if not os.path.exists('V-RAG'):\n",
        "    !git clone https://github.com/sendayildirim/V-RAG\n",
        "    %cd V-RAG\n",
        "else:\n",
        "    %cd V-RAG\n",
        "    !git pull\n",
        "\n",
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "print(\"proje yüklendi\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n"
      ],
      "metadata": {
        "id": "i8z_sTQjnZ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dh2Uddoh9ae"
      },
      "source": [
        "### 1.2 Gerekli Modülleri İçe Aktar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KWI5gjNh9ae"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "from data_loader import DataLoader\n",
        "from chunker import HierarchicalChunker\n",
        "from vector_store import VectorStore\n",
        "from rag_pipeline import RAGPipeline\n",
        "from baseline_model import BaselineModel\n",
        "from metrics import MetricsEvaluator\n",
        "from experiment_runner import ExperimentRunner\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import torch\n",
        "\n",
        "print(\"modüller yüklendi!\")\n",
        "print(f\"GPU kullanılabilme durumu: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YOkP4EIh9ae"
      },
      "source": [
        "---\n",
        "## 2. Veri Hazırlama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wULKTPAUh9af"
      },
      "source": [
        "### 2.1 Kitap ve Soruları İndir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEwrKS6Fh9af"
      },
      "outputs": [],
      "source": [
        "# Data loader oluştur ve verileri indir\n",
        "loader = DataLoader(data_dir=\"data\")\n",
        "data_paths = loader.load_all_data()\n",
        "\n",
        "print(\"\\nİndirilen dosyalar:\")\n",
        "for key, path in data_paths.items():\n",
        "    print(f\"  {key}: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbx6Abuxh9af"
      },
      "source": [
        "### 2.2 Test Verilerini İncele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lryey0PXh9af"
      },
      "outputs": [],
      "source": [
        "# Test sorularını yükle\n",
        "test_df = pd.read_csv(data_paths['test'])\n",
        "\n",
        "print(f\"Toplam test sorusu: {len(test_df)}\")\n",
        "print(\"\\nİlk 3 soru:\")\n",
        "print(test_df[['question', 'answer1', 'answer2']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFDeB0U3h9af"
      },
      "source": [
        "---\n",
        "## 3. Hiyerarşik Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlSpOei6h9af"
      },
      "source": [
        "### 3.1 Chunker Oluştur ve Metni Parçala"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1XTXWQbh9af"
      },
      "outputs": [],
      "source": [
        "# Kitap metnini yükle\n",
        "with open(data_paths['book'], 'r', encoding='utf-8') as f:\n",
        "    book_text = f.read()\n",
        "\n",
        "print(f\"Kitap uzunluğu: {len(book_text)} karakter\")\n",
        "\n",
        "# Chunker oluştur (Parent: 512, Child: 256, Overlap: 50)\n",
        "chunker = HierarchicalChunker(\n",
        "    parent_size=512,\n",
        "    child_size=256,\n",
        "    overlap=50\n",
        ")\n",
        "\n",
        "# Metni parçala\n",
        "parent_chunks, child_chunks = chunker.chunk_text(book_text)\n",
        "\n",
        "# İstatistikler\n",
        "stats = chunker.get_chunk_stats(parent_chunks, child_chunks)\n",
        "print(\"\\nChunk İstatistikleri:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"  {key}: {value:.1f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqjZQA81h9ag"
      },
      "source": [
        "### 3.2 Chunk Örneklerini Görüntüle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPaqZarih9ag"
      },
      "outputs": [],
      "source": [
        "# Bir parent chunk ve onun child'larını göster\n",
        "sample_parent = parent_chunks[0]\n",
        "sample_children = [c for c in child_chunks if c['parent_id'] == sample_parent['id']]\n",
        "\n",
        "print(\"Örnek Parent Chunk:\")\n",
        "print(f\"ID: {sample_parent['id']}\")\n",
        "print(f\"Token sayısı: {sample_parent['token_count']}\")\n",
        "print(f\"Metin (ilk 200 karakter): {sample_parent['text'][:200]}...\")\n",
        "\n",
        "print(\"\\nBu parent'ın child chunk'ları:\")\n",
        "for child in sample_children:\n",
        "    print(f\"  - {child['id']}: {child['token_count']} token\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYyjC5Zmh9ag"
      },
      "source": [
        "---\n",
        "## 4. Vector Store ve Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yl9Wzhlh9ag"
      },
      "source": [
        "### 4.1 Milvus Lite Vector Store Oluştur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmUzZwHkh9ag"
      },
      "outputs": [],
      "source": [
        "# Vector store oluştur\n",
        "vector_store = VectorStore(\n",
        "    db_path=\"./milvus_rag.db\",\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# Collection'ları oluştur\n",
        "vector_store.create_collections()\n",
        "\n",
        "print(f\"Embedding boyutu: {vector_store.embedding_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHiYxOShh9ag"
      },
      "source": [
        "### 4.2 Chunk'ları İndeksle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9yzyv2Rh9ag"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Parent chunk'ları ekle\n",
        "start = time.time()\n",
        "vector_store.insert_parent_chunks(parent_chunks)\n",
        "parent_time = time.time() - start\n",
        "\n",
        "# Child chunk'ları ekle\n",
        "start = time.time()\n",
        "vector_store.insert_child_chunks(child_chunks)\n",
        "child_time = time.time() - start\n",
        "\n",
        "print(f\"\\nParent indexing süresi: {parent_time:.2f}s\")\n",
        "print(f\"Child indexing süresi: {child_time:.2f}s\")\n",
        "print(f\"Toplam indexing süresi: {parent_time + child_time:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqWxDBhxh9ag"
      },
      "source": [
        "### 4.3 Retrieval Testi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj3vGy0jh9ag"
      },
      "outputs": [],
      "source": [
        "# Test sorusu ile retrieval dene\n",
        "test_query = \"Who are Zuleika's most prominent suitors?\"\n",
        "\n",
        "parent_results, child_results = vector_store.hybrid_search(\n",
        "    query=test_query,\n",
        "    top_parents=3,\n",
        "    top_children=5\n",
        ")\n",
        "\n",
        "print(f\"Test sorusu: {test_query}\")\n",
        "print(f\"\\nBulunan {len(child_results)} child chunk:\")\n",
        "for i, result in enumerate(child_results[:3], 1):\n",
        "    print(f\"\\n{i}. Score: {result['score']:.4f}\")\n",
        "    print(f\"   Metin: {result['text'][:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlZeDg58h9ag"
      },
      "source": [
        "---\n",
        "## 5. Baseline Model (RAG'sız)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF_XrtIjh9ag"
      },
      "source": [
        "### 5.1 Baseline Model Oluştur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSIV25vzh9ag"
      },
      "outputs": [],
      "source": [
        "# Baseline model oluştur\n",
        "baseline = BaselineModel(model_name=\"google/gemma-2-2b-it\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p980w-Kh9ag"
      },
      "source": [
        "### 5.2 Baseline ile Test Sorularını Cevapla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbr2dLS9h9ag"
      },
      "outputs": [],
      "source": [
        "# Test sorularını al\n",
        "questions = test_df['question'].tolist()\n",
        "\n",
        "# Baseline ile cevapla\n",
        "print(\"Baseline model ile sorular cevaplanıyor...\")\n",
        "baseline_results = baseline.batch_answer_questions(questions, max_new_tokens=100)\n",
        "\n",
        "print(f\"\\n{len(baseline_results)} soru cevaplandı!\")\n",
        "\n",
        "# İlk 3 cevabı göster\n",
        "print(\"\\nÖrnek Baseline Cevaplar:\")\n",
        "for i, result in enumerate(baseline_results[:3], 1):\n",
        "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
        "    print(f\"   Cevap: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6CaIeUUh9ag"
      },
      "source": [
        "---\n",
        "## 6. RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RMQEgoAh9ag"
      },
      "source": [
        "### 6.1 RAG Pipeline Oluştur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqNratewh9ag"
      },
      "outputs": [],
      "source": [
        "# RAG pipeline oluştur\n",
        "rag_pipeline = RAGPipeline(\n",
        "    vector_store=vector_store,\n",
        "    model_name=\"google/gemma-2-2b-it\",\n",
        "    temperature=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p3stgbuh9ag"
      },
      "source": [
        "### 6.2 RAG ile Test Sorularını Cevapla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJkunDith9ag"
      },
      "outputs": [],
      "source": [
        "# RAG ile cevapla\n",
        "print(\"RAG pipeline ile sorular cevaplanıyor...\")\n",
        "rag_results = rag_pipeline.batch_answer_questions(\n",
        "    questions,\n",
        "    top_k_children=5,\n",
        "    max_new_tokens=100\n",
        ")\n",
        "\n",
        "print(f\"\\n{len(rag_results)} soru cevaplandı!\")\n",
        "\n",
        "# İlk 3 cevabı göster\n",
        "print(\"\\nÖrnek RAG Cevaplar:\")\n",
        "for i, result in enumerate(rag_results[:3], 1):\n",
        "    print(f\"\\n{i}. Soru: {result['question']}\")\n",
        "    print(f\"   Cevap: {result['answer']}\")\n",
        "    print(f\"   Context (ilk 100 karakter): {result['context'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQQVccp3h9ag"
      },
      "source": [
        "---\n",
        "## 7. Performans Değerlendirme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prNRSNKPh9ag"
      },
      "source": [
        "### 7.1 BLEU ve ROUGE Metrikleri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVv9bgzLh9ag"
      },
      "outputs": [],
      "source": [
        "# Metrics evaluator oluştur\n",
        "evaluator = MetricsEvaluator()\n",
        "\n",
        "# RAG vs Baseline karşılaştır\n",
        "comparison = evaluator.compare_models(\n",
        "    rag_results=rag_results,\n",
        "    baseline_results=baseline_results,\n",
        "    ground_truth=test_df\n",
        ")\n",
        "\n",
        "# Sonuçları yazdır\n",
        "evaluator.print_comparison(comparison)\n",
        "\n",
        "# Sonuçları kaydet\n",
        "evaluator.save_results(comparison, \"results/rag_vs_baseline.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMKXXZmh9ag"
      },
      "source": [
        "### 7.2 Sonuçları Görselleştir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJnN43Zxh9ah"
      },
      "outputs": [],
      "source": [
        "# Karşılaştırma grafiği\n",
        "metrics = ['bleu', 'rouge1', 'rouge2', 'rougeL']\n",
        "rag_scores = [comparison['rag'][m] for m in metrics]\n",
        "baseline_scores = [comparison['baseline'][m] for m in metrics]\n",
        "\n",
        "x = range(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar([i - width/2 for i in x], rag_scores, width, label='RAG', color='#2ecc71')\n",
        "ax.bar([i + width/2 for i in x], baseline_scores, width, label='Baseline', color='#e74c3c')\n",
        "\n",
        "ax.set_xlabel('Metrikler', fontsize=12)\n",
        "ax.set_ylabel('Skor', fontsize=12)\n",
        "ax.set_title('RAG vs Baseline Performans Karşılaştırması', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([m.upper() for m in metrics])\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/rag_vs_baseline.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Grafik kaydedildi: results/rag_vs_baseline.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQRyJFj3h9am"
      },
      "source": [
        "---\n",
        "## 8. Hiperparametre Optimizasyonu (Opsiyonel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsxd9KQHh9am"
      },
      "source": [
        "### 8.1 Grid Search Hazırlığı\n",
        "\n",
        "**UYARI:** Bu bölüm çok uzun sürer (60 deney × ~5-10 dakika = ~5-10 saat).\n",
        "Sadece küçük bir subset ile test edin veya Colab Pro ile çalıştırın."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM4wwp8Jh9am"
      },
      "outputs": [],
      "source": [
        "# Grid search parametreleri\n",
        "CHUNK_SIZES = [128, 256, 512]\n",
        "OVERLAPS = [0, 25, 50, 100]\n",
        "TEMPERATURES = [0.1, 0.2, 0.4, 0.6, 0.8]\n",
        "\n",
        "total_experiments = len(CHUNK_SIZES) * len(OVERLAPS) * len(TEMPERATURES)\n",
        "print(f\"Toplam deney sayısı: {total_experiments}\")\n",
        "print(f\"Tahmini süre: {total_experiments * 5} - {total_experiments * 10} dakika\")\n",
        "print(\"\\nDikkat: Bu uzun sürecektir! Küçük bir subset ile test etmeyi düşünün.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jWPjjkh9am"
      },
      "source": [
        "### 8.2 Grid Search Çalıştır (Küçük Subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HViwDZAh9am"
      },
      "outputs": [],
      "source": [
        "# Küçük bir subset ile test\n",
        "CHUNK_SIZES_SUBSET = [256, 512]\n",
        "OVERLAPS_SUBSET = [25, 50]\n",
        "TEMPERATURES_SUBSET = [0.1, 0.4]\n",
        "\n",
        "# Experiment runner oluştur\n",
        "runner = ExperimentRunner(\n",
        "    book_path=data_paths['book'],\n",
        "    test_questions_path=data_paths['test'],\n",
        "    results_dir=\"results/experiments\"\n",
        ")\n",
        "\n",
        "# Grid search çalıştır\n",
        "print(\"Grid search başlatılıyor (subset)...\")\n",
        "all_results = runner.run_grid_search(\n",
        "    chunk_sizes=CHUNK_SIZES_SUBSET,\n",
        "    overlaps=OVERLAPS_SUBSET,\n",
        "    temperatures=TEMPERATURES_SUBSET\n",
        ")\n",
        "\n",
        "# Sonuçları kaydet\n",
        "runner.save_summary(all_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD78IZWHh9am"
      },
      "source": [
        "### 8.3 Experiment Sonuçlarını Analiz Et"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6QhjVRxh9am"
      },
      "outputs": [],
      "source": [
        "# Sonuçları yükle\n",
        "exp_df = pd.read_csv('results/experiments/experiment_summary.csv')\n",
        "\n",
        "print(\"Experiment Özeti:\")\n",
        "print(exp_df[['child_size', 'overlap', 'temperature', 'bleu', 'rouge1', 'rougeL', 'total_time']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_ahKJG7h9am"
      },
      "source": [
        "### 8.4 En İyi Parametreleri Bul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZePm1aG7h9am"
      },
      "outputs": [],
      "source": [
        "# BLEU'ya göre sırala\n",
        "best_bleu = exp_df.nlargest(5, 'bleu')[['child_size', 'overlap', 'temperature', 'bleu', 'total_time']]\n",
        "print(\"En Yüksek BLEU Skorları:\")\n",
        "print(best_bleu)\n",
        "\n",
        "# ROUGE-L'ye göre sırala\n",
        "best_rougeL = exp_df.nlargest(5, 'rougeL')[['child_size', 'overlap', 'temperature', 'rougeL', 'total_time']]\n",
        "print(\"\\nEn Yüksek ROUGE-L Skorları:\")\n",
        "print(best_rougeL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab7vxqzbh9am"
      },
      "source": [
        "### 8.5 Parametre Etkilerini Görselleştir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfLsqLsxh9am"
      },
      "outputs": [],
      "source": [
        "# Chunk size etkisi\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Chunk size vs BLEU\n",
        "exp_df.groupby('child_size')['bleu'].mean().plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Chunk Size vs BLEU')\n",
        "axes[0].set_xlabel('Child Chunk Size')\n",
        "axes[0].set_ylabel('Ortalama BLEU')\n",
        "\n",
        "# Overlap vs ROUGE-L\n",
        "exp_df.groupby('overlap')['rougeL'].mean().plot(kind='bar', ax=axes[1], color='lightcoral')\n",
        "axes[1].set_title('Overlap vs ROUGE-L')\n",
        "axes[1].set_xlabel('Overlap')\n",
        "axes[1].set_ylabel('Ortalama ROUGE-L')\n",
        "\n",
        "# Temperature vs ROUGE-1\n",
        "exp_df.groupby('temperature')['rouge1'].mean().plot(kind='bar', ax=axes[2], color='lightgreen')\n",
        "axes[2].set_title('Temperature vs ROUGE-1')\n",
        "axes[2].set_xlabel('Temperature')\n",
        "axes[2].set_ylabel('Ortalama ROUGE-1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/parameter_effects.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Grafik kaydedildi: results/parameter_effects.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWAk9C9Ph9am"
      },
      "source": [
        "---\n",
        "## 9. Kaynak Kullanımı Analizi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTGjsnu2h9am"
      },
      "source": [
        "### 9.1 Memory ve Time Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQASV48Qh9am"
      },
      "outputs": [],
      "source": [
        "if len(exp_df) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Memory kullanımı\n",
        "    exp_df.plot(x='child_size', y='memory_used_mb', kind='scatter', ax=axes[0], s=100, alpha=0.6)\n",
        "    axes[0].set_title('Chunk Size vs Memory Kullanımı')\n",
        "    axes[0].set_xlabel('Child Chunk Size')\n",
        "    axes[0].set_ylabel('Memory (MB)')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Execution time\n",
        "    exp_df.plot(x='child_size', y='total_time', kind='scatter', ax=axes[1], s=100, alpha=0.6, color='orange')\n",
        "    axes[1].set_title('Chunk Size vs Toplam Süre')\n",
        "    axes[1].set_xlabel('Child Chunk Size')\n",
        "    axes[1].set_ylabel('Süre (saniye)')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/resource_usage.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Grafik kaydedildi: results/resource_usage.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lnwTdlxh9am"
      },
      "source": [
        "### 9.2 Database Boyutu Analizi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H6KhZbph9an"
      },
      "outputs": [],
      "source": [
        "if len(exp_df) > 0:\n",
        "    # DB boyutlarını göster\n",
        "    db_stats = exp_df.groupby('child_size')['db_size_mb'].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    db_stats.plot(kind='bar', color='purple', alpha=0.7)\n",
        "    plt.title('Ortalama Vector DB Boyutu')\n",
        "    plt.xlabel('Child Chunk Size')\n",
        "    plt.ylabel('DB Boyutu (MB)')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/db_size.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Grafik kaydedildi: results/db_size.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_z27fVh9an"
      },
      "source": [
        "---\n",
        "## 10. Sonuç ve Gözlemler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROEFg4r6h9an"
      },
      "source": [
        "### 10.1 Ana Bulgular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmAm4rulh9an"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"PROJE ÖZETI VE BULGULAR\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. RAG vs Baseline Performansı:\")\n",
        "print(f\"   - RAG BLEU: {comparison['rag']['bleu']:.2f}\")\n",
        "print(f\"   - Baseline BLEU: {comparison['baseline']['bleu']:.2f}\")\n",
        "print(f\"   - İyileştirme: {comparison['improvement']['bleu']:+.2f}\")\n",
        "\n",
        "if len(exp_df) > 0:\n",
        "    print(\"\\n2. En İyi Parametre Kombinasyonu:\")\n",
        "    best = exp_df.loc[exp_df['bleu'].idxmax()]\n",
        "    print(f\"   - Chunk Size: {best['child_size']}\")\n",
        "    print(f\"   - Overlap: {best['overlap']}\")\n",
        "    print(f\"   - Temperature: {best['temperature']}\")\n",
        "    print(f\"   - BLEU: {best['bleu']:.2f}\")\n",
        "\n",
        "print(\"\\n3. Kaynak Kullanımı:\")\n",
        "print(f\"   - Ortalama indexing süresi: {(parent_time + child_time):.2f}s\")\n",
        "print(f\"   - GPU kullanımı: {'Evet' if torch.cuda.is_available() else 'Hayır'}\")\n",
        "\n",
        "print(\"\\n4. Zorluklar ve Gözlemler:\")\n",
        "print(\"   - Google Colab kaynak kısıtları nedeniyle grid search uzun sürdü\")\n",
        "print(\"   - Hiyerarşik chunking, context kalitesini artırdı\")\n",
        "print(\"   - Optimal chunk size ve overlap değerleri veri setine bağlı\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKidN1wyh9an"
      },
      "source": [
        "### 10.2 Tüm Sonuçları Dışa Aktar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZJ2ZaJ1h9an"
      },
      "outputs": [],
      "source": [
        "# Tüm sonuçları bir yerde topla\n",
        "final_report = {\n",
        "    'project_info': {\n",
        "        'book': 'Zuleika Dobson by Max Beerbohm',\n",
        "        'dataset': 'NarrativeQA',\n",
        "        'test_questions': len(test_df),\n",
        "        'vector_db': 'Milvus Lite',\n",
        "        'embedding_model': 'all-MiniLM-L6-v2',\n",
        "        'llm': 'google/gemma-2-2b-it'\n",
        "    },\n",
        "    'chunk_stats': stats,\n",
        "    'rag_vs_baseline': comparison,\n",
        "    'best_config': exp_df.loc[exp_df['bleu'].idxmax()].to_dict() if len(exp_df) > 0 else None\n",
        "}\n",
        "\n",
        "# JSON olarak kaydet\n",
        "with open('results/final_report.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Final rapor kaydedildi: results/final_report.json\")\n",
        "print(\"\\nProje tamamlandı!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asmC3hQFh9an"
      },
      "source": [
        "---\n",
        "## Notlar ve İyileştirme Önerileri\n",
        "\n",
        "### Gözlemler:\n",
        "1. **Hiyerarşik Chunking:** Parent-child yapısı, hem geniş context hem de detaylı bilgi sağladı\n",
        "2. **Milvus Lite:** Disk-based yapısı Colab için ideal, memory kullanımı düşük\n",
        "3. **Hyperparameter Tuning:** Chunk size, overlap ve temperature'ün kombinasyonu performansı etkiliyor\n",
        "\n",
        "### İyileştirme Önerileri:\n",
        "1. Reranking mekanizması eklenebilir (Cross-encoder)\n",
        "2. Query expansion ile retrieval kalitesi artırılabilir\n",
        "3. Daha büyük LLM'ler (7B, 13B) test edilebilir\n",
        "4. Multi-hop reasoning için iterative retrieval denenebilir\n",
        "\n",
        "### Colab Kullanım Tavsiyeleri:\n",
        "- GPU runtime kullanın (Runtime → Change runtime type → GPU)\n",
        "- Uzun süren işlemler için Colab Pro düşünün\n",
        "- Checkpoint'ler kaydedin (disconnect olursa devam edebilmek için)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}